{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "312ddf1c",
   "metadata": {},
   "source": [
    "# Analysing the Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53517dd8",
   "metadata": {},
   "source": [
    "Importing the ODI ball by ball data from 2015 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ec83f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\othma\\AppData\\Local\\Temp\\ipykernel_21296\\405764276.py:11: DtypeWarning: Columns (1,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(data_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file from: C:\\Github\\dst_assessment1\\YoussefO\\data\\odi_bbb_recent.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>season</th>\n",
       "      <th>start_date</th>\n",
       "      <th>venue</th>\n",
       "      <th>innings</th>\n",
       "      <th>ball</th>\n",
       "      <th>batting_team</th>\n",
       "      <th>bowling_team</th>\n",
       "      <th>striker</th>\n",
       "      <th>non_striker</th>\n",
       "      <th>...</th>\n",
       "      <th>player_dismissed</th>\n",
       "      <th>other_wicket_type</th>\n",
       "      <th>other_player_dismissed</th>\n",
       "      <th>winner</th>\n",
       "      <th>toss_winner</th>\n",
       "      <th>toss_decision</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>bowling_style</th>\n",
       "      <th>batting_style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>749781</td>\n",
       "      <td>2014/15</td>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>Hagley Oval</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>FDM Karunaratne</td>\n",
       "      <td>TM Dilshan</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>bat</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>Left arm Fast medium</td>\n",
       "      <td>Left hand Bat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>749781</td>\n",
       "      <td>2014/15</td>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>Hagley Oval</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>TM Dilshan</td>\n",
       "      <td>FDM Karunaratne</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>bat</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>Left arm Fast medium</td>\n",
       "      <td>Right hand Bat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>749781</td>\n",
       "      <td>2014/15</td>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>Hagley Oval</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>TM Dilshan</td>\n",
       "      <td>FDM Karunaratne</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>bat</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>Left arm Fast medium</td>\n",
       "      <td>Right hand Bat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>749781</td>\n",
       "      <td>2014/15</td>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>Hagley Oval</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>TM Dilshan</td>\n",
       "      <td>FDM Karunaratne</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>bat</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>Left arm Fast medium</td>\n",
       "      <td>Right hand Bat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>749781</td>\n",
       "      <td>2014/15</td>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>Hagley Oval</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>TM Dilshan</td>\n",
       "      <td>FDM Karunaratne</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>bat</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>Left arm Fast medium</td>\n",
       "      <td>Right hand Bat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id   season  start_date        venue  innings  ball batting_team  \\\n",
       "0    749781  2014/15  2015-01-11  Hagley Oval        1   0.1    Sri Lanka   \n",
       "1    749781  2014/15  2015-01-11  Hagley Oval        1   0.2    Sri Lanka   \n",
       "2    749781  2014/15  2015-01-11  Hagley Oval        1   0.3    Sri Lanka   \n",
       "3    749781  2014/15  2015-01-11  Hagley Oval        1   0.4    Sri Lanka   \n",
       "4    749781  2014/15  2015-01-11  Hagley Oval        1   0.5    Sri Lanka   \n",
       "\n",
       "  bowling_team          striker      non_striker  ... player_dismissed  \\\n",
       "0  New Zealand  FDM Karunaratne       TM Dilshan  ...              NaN   \n",
       "1  New Zealand       TM Dilshan  FDM Karunaratne  ...              NaN   \n",
       "2  New Zealand       TM Dilshan  FDM Karunaratne  ...              NaN   \n",
       "3  New Zealand       TM Dilshan  FDM Karunaratne  ...              NaN   \n",
       "4  New Zealand       TM Dilshan  FDM Karunaratne  ...              NaN   \n",
       "\n",
       "   other_wicket_type  other_player_dismissed       winner  toss_winner  \\\n",
       "0                NaN                     NaN  New Zealand    Sri Lanka   \n",
       "1                NaN                     NaN  New Zealand    Sri Lanka   \n",
       "2                NaN                     NaN  New Zealand    Sri Lanka   \n",
       "3                NaN                     NaN  New Zealand    Sri Lanka   \n",
       "4                NaN                     NaN  New Zealand    Sri Lanka   \n",
       "\n",
       "   toss_decision        team1      team2         bowling_style   batting_style  \n",
       "0            bat  New Zealand  Sri Lanka  Left arm Fast medium   Left hand Bat  \n",
       "1            bat  New Zealand  Sri Lanka  Left arm Fast medium  Right hand Bat  \n",
       "2            bat  New Zealand  Sri Lanka  Left arm Fast medium  Right hand Bat  \n",
       "3            bat  New Zealand  Sri Lanka  Left arm Fast medium  Right hand Bat  \n",
       "4            bat  New Zealand  Sri Lanka  Left arm Fast medium  Right hand Bat  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Get the project root dynamically (the parent of the notebook folder)\n",
    "project_root = Path(__file__).resolve().parents[1] if \"__file__\" in locals() else Path().resolve().parents[0]\n",
    "\n",
    "# Build the path to the CSV\n",
    "data_path = project_root / \"data\" / \"odi_bbb_recent.csv\"\n",
    "\n",
    "# Read the CSV\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Loaded file from: {data_path}\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ed753b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['match_id', 'season', 'start_date', 'venue', 'innings', 'ball',\n",
       "       'batting_team', 'bowling_team', 'striker', 'non_striker', 'bowler',\n",
       "       'runs_off_bat', 'extras', 'wides', 'noballs', 'byes', 'legbyes',\n",
       "       'penalty', 'wicket_type', 'player_dismissed', 'other_wicket_type',\n",
       "       'other_player_dismissed', 'winner', 'toss_winner', 'toss_decision',\n",
       "       'team1', 'team2', 'bowling_style', 'batting_style'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04791590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620647, 29)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4313b2d7",
   "metadata": {},
   "source": [
    "## Feature Generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac946a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert ball column to numeric over (e.g., 1.1 -> over 1)\n",
    "data['over'] = data['ball'].astype(float).apply(lambda x: int(x))\n",
    "\n",
    "# Filter for first 10 overs only\n",
    "data_10_overs = data[data['over'] < 10].copy()\n",
    "\n",
    "# Calculate total runs per ball (runs_off_bat + extras)\n",
    "data_10_overs['total_runs'] = data_10_overs['runs_off_bat'] + data_10_overs['extras']\n",
    "\n",
    "# Identify boundaries\n",
    "data_10_overs['is_four'] = (data_10_overs['runs_off_bat'] == 4).astype(int)\n",
    "data_10_overs['is_six'] = (data_10_overs['runs_off_bat'] == 6).astype(int)\n",
    "data_10_overs['is_boundary'] = ((data_10_overs['runs_off_bat'] == 4) | \n",
    "                                    (data_10_overs['runs_off_bat'] == 6)).astype(int)\n",
    "\n",
    "# Identify dot balls (no runs scored)\n",
    "data_10_overs['is_dot'] = (data_10_overs['total_runs'] == 0).astype(int)\n",
    "\n",
    "# Identify wickets\n",
    "data_10_overs['is_wicket'] = data_10_overs['wicket_type'].notna().astype(int)\n",
    "\n",
    "# Aggregate statistics by match and innings\n",
    "match_innings_stats = data_10_overs.groupby(['match_id', 'innings']).agg({\n",
    "    'total_runs': 'sum',           # Total runs in first 10 overs\n",
    "    'runs_off_bat': 'sum',         # Runs off bat (excluding extras)\n",
    "    'extras': 'sum',               # Total extras\n",
    "    'wides': 'sum',                # Wide balls\n",
    "    'noballs': 'sum',              # No balls\n",
    "    'is_wicket': 'sum',            # Wickets lost\n",
    "    'is_dot': 'sum',               # Dot balls\n",
    "    'is_four': 'sum',              # Number of fours\n",
    "    'is_six': 'sum',               # Number of sixes\n",
    "    'is_boundary': 'sum',          # Total boundaries\n",
    "    'ball': 'count'                # Total balls bowled\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "match_innings_stats.columns = [\n",
    "    'match_id', 'innings', 'total_runs', 'runs_off_bat', 'total_extras',\n",
    "    'wides', 'noballs', 'wickets', 'dot_balls', 'fours', 'sixes', \n",
    "    'boundaries', 'balls_bowled'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa6459b",
   "metadata": {},
   "source": [
    "Now that we have sucessfully preprocessed the data.\n",
    "We now engineer some metrics to help classify which team is most likely to win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39ad43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate derived metrics\n",
    "match_innings_stats['run_rate'] = (match_innings_stats['total_runs'] / \n",
    "                                    match_innings_stats['balls_bowled'] * 6)\n",
    "match_innings_stats['dot_ball_percentage'] = (match_innings_stats['dot_balls'] / \n",
    "                                                match_innings_stats['balls_bowled'] * 100)\n",
    "match_innings_stats['boundary_percentage'] = (match_innings_stats['boundaries'] / \n",
    "                                                match_innings_stats['balls_bowled'] * 100)\n",
    "match_innings_stats['extras_per_over'] = (match_innings_stats['total_extras'] / 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6045e430",
   "metadata": {},
   "source": [
    "We then make sure we have seperate data for the first 10 balls of each innings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Separate innings 1 and innings 2\n",
    "innings1 = match_innings_stats[match_innings_stats['innings'] == 1].copy()\n",
    "innings2 = match_innings_stats[match_innings_stats['innings'] == 2].copy()\n",
    "\n",
    "# Rename columns to distinguish between innings\n",
    "innings1_cols = {col: f'team1_{col}' for col in innings1.columns \n",
    "                    if col not in ['match_id', 'innings']}\n",
    "innings2_cols = {col: f'team2_{col}' for col in innings2.columns \n",
    "                    if col not in ['match_id', 'innings']}\n",
    "\n",
    "innings1 = innings1.rename(columns=innings1_cols).drop('innings', axis=1)\n",
    "innings2 = innings2.rename(columns=innings2_cols).drop('innings', axis=1)\n",
    "\n",
    "# Merge innings data\n",
    "match_features = pd.merge(innings1, innings2, on='match_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eaaeb5",
   "metadata": {},
   "source": [
    "We get the match metadata (season, start_date, ...) and merge it with our match features for a complete dataset with features and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eab2aa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>team1_total_runs</th>\n",
       "      <th>team1_runs_off_bat</th>\n",
       "      <th>team1_total_extras</th>\n",
       "      <th>team1_wides</th>\n",
       "      <th>team1_noballs</th>\n",
       "      <th>team1_wickets</th>\n",
       "      <th>team1_dot_balls</th>\n",
       "      <th>team1_fours</th>\n",
       "      <th>team1_sixes</th>\n",
       "      <th>...</th>\n",
       "      <th>team2_boundary_percentage</th>\n",
       "      <th>team2_extras_per_over</th>\n",
       "      <th>season</th>\n",
       "      <th>start_date</th>\n",
       "      <th>venue</th>\n",
       "      <th>winner</th>\n",
       "      <th>toss_winner</th>\n",
       "      <th>toss_decision</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656399</td>\n",
       "      <td>77</td>\n",
       "      <td>71</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014/15</td>\n",
       "      <td>2015-02-14</td>\n",
       "      <td>Hagley Oval</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>field</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Sri Lanka</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  team1_total_runs  team1_runs_off_bat  team1_total_extras  \\\n",
       "0    656399                77                  71                   6   \n",
       "\n",
       "   team1_wides  team1_noballs  team1_wickets  team1_dot_balls  team1_fours  \\\n",
       "0          2.0            2.0              0               31           10   \n",
       "\n",
       "   team1_sixes  ...  team2_boundary_percentage  team2_extras_per_over  \\\n",
       "0            1  ...                  11.666667                    0.0   \n",
       "\n",
       "    season  start_date        venue       winner  toss_winner  toss_decision  \\\n",
       "0  2014/15  2015-02-14  Hagley Oval  New Zealand    Sri Lanka          field   \n",
       "\n",
       "         team1      team2  \n",
       "0  New Zealand  Sri Lanka  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get match metadata (take first row per match from original data)\n",
    "match_metadata = data.groupby('match_id').first()[\n",
    "    ['season', 'start_date', 'venue', 'winner', 'toss_winner', \n",
    "        'toss_decision', 'team1', 'team2']\n",
    "].reset_index()\n",
    "\n",
    "# Merge with features\n",
    "final_data = pd.merge(match_features, match_metadata, on='match_id', how='left')\n",
    "\n",
    "final_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ad0d7",
   "metadata": {},
   "source": [
    "Now we convert the main response variable 'The Winner' into a binary 0 or 1 variable. Similarly, we categorise the toss winner (0/1) and toss decision (0/1). Calculate some more metrics to gauge how the two teams are doing after their first 10 balls.\n",
    "\n",
    "Crucially we also categorise the venues, teams and the season in which they played the match in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bbcc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create binary winner variable (1 if team1 wins, 0 if team2 wins)\n",
    "final_data['winner_binary'] = (final_data['winner'] == final_data['team1']).astype(int)\n",
    "\n",
    "# Create toss winner binary (1 if team1 won toss, 0 otherwise)\n",
    "final_data['toss_won_by_team1'] = (final_data['toss_winner'] == final_data['team1']).astype(int)\n",
    "\n",
    "# Create toss decision binary (1 if bat first, 0 if field first)\n",
    "final_data['toss_decision_bat'] = (final_data['toss_decision'] == 'bat').astype(int)\n",
    "\n",
    "# Calculate relative performance metrics\n",
    "final_data['runs_difference'] = final_data['team1_total_runs'] - final_data['team2_total_runs']\n",
    "final_data['wickets_difference'] = final_data['team1_wickets'] - final_data['team2_wickets']\n",
    "final_data['run_rate_difference'] = final_data['team1_run_rate'] - final_data['team2_run_rate']\n",
    "final_data['boundary_difference'] = final_data['team1_boundaries'] - final_data['team2_boundaries']\n",
    "\n",
    "# Create venue and team categorical encodings (for mixed effects)\n",
    "final_data['venue_encoded'] = pd.Categorical(final_data['venue']).codes\n",
    "final_data['team1_encoded'] = pd.Categorical(final_data['team1']).codes\n",
    "final_data['team2_encoded'] = pd.Categorical(final_data['team2']).codes\n",
    "final_data['season_encoded'] = pd.Categorical(final_data['season']).codes\n",
    "\n",
    "# Sort by match_id for consistency\n",
    "final_data = final_data.sort_values('match_id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5459cc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>team1_total_runs</th>\n",
       "      <th>team1_runs_off_bat</th>\n",
       "      <th>team1_total_extras</th>\n",
       "      <th>team1_wides</th>\n",
       "      <th>team1_noballs</th>\n",
       "      <th>team1_wickets</th>\n",
       "      <th>team1_dot_balls</th>\n",
       "      <th>team1_fours</th>\n",
       "      <th>team1_sixes</th>\n",
       "      <th>...</th>\n",
       "      <th>team2_boundary_percentage</th>\n",
       "      <th>team2_extras_per_over</th>\n",
       "      <th>season</th>\n",
       "      <th>start_date</th>\n",
       "      <th>venue</th>\n",
       "      <th>winner</th>\n",
       "      <th>toss_winner</th>\n",
       "      <th>toss_decision</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656399</td>\n",
       "      <td>77</td>\n",
       "      <td>71</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014/15</td>\n",
       "      <td>2015-02-14</td>\n",
       "      <td>Hagley Oval</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>field</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Sri Lanka</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  team1_total_runs  team1_runs_off_bat  team1_total_extras  \\\n",
       "0    656399                77                  71                   6   \n",
       "\n",
       "   team1_wides  team1_noballs  team1_wickets  team1_dot_balls  team1_fours  \\\n",
       "0          2.0            2.0              0               31           10   \n",
       "\n",
       "   team1_sixes  ...  team2_boundary_percentage  team2_extras_per_over  \\\n",
       "0            1  ...                  11.666667                    0.0   \n",
       "\n",
       "    season  start_date        venue       winner  toss_winner  toss_decision  \\\n",
       "0  2014/15  2015-02-14  Hagley Oval  New Zealand    Sri Lanka          field   \n",
       "\n",
       "         team1      team2  \n",
       "0  New Zealand  Sri Lanka  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0901c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_cricket_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess cricket ball-by-ball data for match outcome prediction.\n",
    "    Focuses on first 10 overs performance of both teams.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        Ball-by-ball cricket data with required columns\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    processed_df : pandas DataFrame\n",
    "        Aggregated match-level features with binary winner variable\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    data = df.copy()\n",
    "    \n",
    "    # ===== DATA CLEANING =====\n",
    "    \n",
    "    # 1. Fill NAs in extras columns with 0 (if a ball didn't have that extra, it's 0)\n",
    "    extras_cols = ['wides', 'noballs', 'byes', 'legbyes', 'penalty', 'extras']\n",
    "    for col in extras_cols:\n",
    "        if col in data.columns:\n",
    "            data[col] = data[col].fillna(0)\n",
    "    \n",
    "    # 2. Fill NAs in runs_off_bat with 0\n",
    "    data['runs_off_bat'] = data['runs_off_bat'].fillna(0)\n",
    "    \n",
    "    # 3. Remove matches with missing critical information\n",
    "    # Keep only matches where we have both team1, team2, and winner\n",
    "    data = data.dropna(subset=['match_id', 'innings', 'ball', 'team1', 'team2', 'winner'])\n",
    "    \n",
    "    # 4. Remove matches where winner is neither team1 nor team2 \n",
    "    # (ties, no results, abandoned matches)\n",
    "    valid_winners = (data['winner'] == data['team1']) | (data['winner'] == data['team2'])\n",
    "    data = data[valid_winners].copy()\n",
    "    \n",
    "    # 5. Keep only matches with both innings present\n",
    "    innings_count = data.groupby('match_id')['innings'].nunique()\n",
    "    valid_matches = innings_count[innings_count == 2].index\n",
    "    data = data[data['match_id'].isin(valid_matches)].copy()\n",
    "    \n",
    "    # Convert ball column to numeric over (e.g., 1.1 -> over 1)\n",
    "    data['over'] = data['ball'].astype(float).apply(lambda x: int(x))\n",
    "    \n",
    "    # Filter for first 10 overs only (overs 0-9 or 1-10 depending on notation)\n",
    "    # Checking the unique values to understand the notation\n",
    "    data_10_overs = data[data['over'] < 10].copy()\n",
    "    \n",
    "    # Calculate total runs per ball (runs_off_bat + extras)\n",
    "    data_10_overs['total_runs'] = data_10_overs['runs_off_bat'] + data_10_overs['extras']\n",
    "    \n",
    "    # Identify boundaries\n",
    "    data_10_overs['is_four'] = (data_10_overs['runs_off_bat'] == 4).astype(int)\n",
    "    data_10_overs['is_six'] = (data_10_overs['runs_off_bat'] == 6).astype(int)\n",
    "    data_10_overs['is_boundary'] = ((data_10_overs['runs_off_bat'] == 4) | \n",
    "                                     (data_10_overs['runs_off_bat'] == 6)).astype(int)\n",
    "    \n",
    "    # Identify dot balls (no runs scored)\n",
    "    data_10_overs['is_dot'] = (data_10_overs['total_runs'] == 0).astype(int)\n",
    "    \n",
    "    # Identify wickets\n",
    "    data_10_overs['is_wicket'] = data_10_overs['wicket_type'].notna().astype(int)\n",
    "    \n",
    "    # Aggregate statistics by match and innings\n",
    "    match_innings_stats = data_10_overs.groupby(['match_id', 'innings']).agg({\n",
    "        'total_runs': 'sum',           # Total runs in first 10 overs\n",
    "        'runs_off_bat': 'sum',         # Runs off bat (excluding extras)\n",
    "        'extras': 'sum',               # Total extras\n",
    "        'wides': 'sum',                # Wide balls\n",
    "        'noballs': 'sum',              # No balls\n",
    "        'is_wicket': 'sum',            # Wickets lost\n",
    "        'is_dot': 'sum',               # Dot balls\n",
    "        'is_four': 'sum',              # Number of fours\n",
    "        'is_six': 'sum',               # Number of sixes\n",
    "        'is_boundary': 'sum',          # Total boundaries\n",
    "        'ball': 'count'                # Total balls bowled\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    match_innings_stats.columns = [\n",
    "        'match_id', 'innings', 'total_runs', 'runs_off_bat', 'total_extras',\n",
    "        'wides', 'noballs', 'wickets', 'dot_balls', 'fours', 'sixes', \n",
    "        'boundaries', 'balls_bowled'\n",
    "    ]\n",
    "    \n",
    "    # Calculate derived metrics\n",
    "    match_innings_stats['run_rate'] = (match_innings_stats['total_runs'] / \n",
    "                                        match_innings_stats['balls_bowled'] * 6)\n",
    "    match_innings_stats['dot_ball_percentage'] = (match_innings_stats['dot_balls'] / \n",
    "                                                   match_innings_stats['balls_bowled'] * 100)\n",
    "    match_innings_stats['boundary_percentage'] = (match_innings_stats['boundaries'] / \n",
    "                                                   match_innings_stats['balls_bowled'] * 100)\n",
    "    match_innings_stats['extras_per_over'] = (match_innings_stats['total_extras'] / 10)\n",
    "    \n",
    "    # Separate innings 1 and innings 2\n",
    "    innings1 = match_innings_stats[match_innings_stats['innings'] == 1].copy()\n",
    "    innings2 = match_innings_stats[match_innings_stats['innings'] == 2].copy()\n",
    "    \n",
    "    # Rename columns to distinguish between innings\n",
    "    innings1_cols = {col: f'team1_{col}' for col in innings1.columns \n",
    "                     if col not in ['match_id', 'innings']}\n",
    "    innings2_cols = {col: f'team2_{col}' for col in innings2.columns \n",
    "                     if col not in ['match_id', 'innings']}\n",
    "    \n",
    "    innings1 = innings1.rename(columns=innings1_cols).drop('innings', axis=1)\n",
    "    innings2 = innings2.rename(columns=innings2_cols).drop('innings', axis=1)\n",
    "    \n",
    "    # Merge innings data - use inner join to only keep complete matches\n",
    "    match_features = pd.merge(innings1, innings2, on='match_id', how='inner')\n",
    "    \n",
    "    # Get match metadata (take first row per match from original data)\n",
    "    match_metadata = data.groupby('match_id').first()[\n",
    "        ['season', 'start_date', 'venue', 'winner', 'toss_winner', \n",
    "         'toss_decision', 'team1', 'team2']\n",
    "    ].reset_index()\n",
    "    \n",
    "    # Merge with features\n",
    "    final_data = pd.merge(match_features, match_metadata, on='match_id', how='left')\n",
    "    \n",
    "    # Drop any remaining rows with NAs in critical columns\n",
    "    final_data = final_data.dropna(subset=['winner', 'team1', 'team2'])\n",
    "    \n",
    "    # Create binary winner variable (1 if team1 wins, 0 if team2 wins)\n",
    "    final_data['winner_binary'] = (final_data['winner'] == final_data['team1']).astype(int)\n",
    "    \n",
    "    # Create toss winner binary (1 if team1 won toss, 0 otherwise)\n",
    "    final_data['toss_won_by_team1'] = (final_data['toss_winner'] == final_data['team1']).astype(int)\n",
    "    \n",
    "    # Create toss decision binary (1 if bat first, 0 if field first)\n",
    "    final_data['toss_decision_bat'] = (final_data['toss_decision'] == 'bat').astype(int)\n",
    "    \n",
    "    # Calculate relative performance metrics\n",
    "    final_data['runs_difference'] = final_data['team1_total_runs'] - final_data['team2_total_runs']\n",
    "    final_data['wickets_difference'] = final_data['team1_wickets'] - final_data['team2_wickets']\n",
    "    final_data['run_rate_difference'] = final_data['team1_run_rate'] - final_data['team2_run_rate']\n",
    "    final_data['boundary_difference'] = final_data['team1_boundaries'] - final_data['team2_boundaries']\n",
    "    \n",
    "    # Create venue and team categorical encodings (for mixed effects)\n",
    "    final_data['venue_encoded'] = pd.Categorical(final_data['venue']).codes\n",
    "    final_data['team1_encoded'] = pd.Categorical(final_data['team1']).codes\n",
    "    final_data['team2_encoded'] = pd.Categorical(final_data['team2']).codes\n",
    "    final_data['season_encoded'] = pd.Categorical(final_data['season']).codes\n",
    "    \n",
    "    # Sort by match_id for consistency\n",
    "    final_data = final_data.sort_values('match_id').reset_index(drop=True)\n",
    "    \n",
    "    # Final check: ensure no NAs in key modeling columns\n",
    "    modeling_cols = ['winner_binary', 'team1_total_runs', 'team2_total_runs',\n",
    "                     'team1_wickets', 'team2_wickets', 'team1_run_rate', 'team2_run_rate']\n",
    "    final_data = final_data.dropna(subset=modeling_cols)\n",
    "    \n",
    "    return final_data\n",
    "\n",
    "\n",
    "def check_data_quality(df):\n",
    "    \"\"\"\n",
    "    Check for missing values and data quality issues before preprocessing.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"DATA QUALITY CHECK\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Check for missing values in critical columns\n",
    "    critical_cols = ['match_id', 'innings', 'ball', 'batting_team', 'bowling_team',\n",
    "                     'runs_off_bat', 'extras', 'winner', 'team1', 'team2']\n",
    "    \n",
    "    print(\"\\nMissing values in critical columns:\")\n",
    "    missing_critical = df[critical_cols].isna().sum()\n",
    "    if missing_critical.sum() == 0:\n",
    "        print(\"  ✓ No missing values in critical columns\")\n",
    "    else:\n",
    "        print(missing_critical[missing_critical > 0])\n",
    "    \n",
    "    # Check wicket-related columns (expected to have NAs when no wicket)\n",
    "    wicket_cols = ['wicket_type', 'player_dismissed', 'other_wicket_type', \n",
    "                   'other_player_dismissed']\n",
    "    print(f\"\\nWicket-related columns (NAs expected when no wicket):\")\n",
    "    for col in wicket_cols:\n",
    "        if col in df.columns:\n",
    "            na_count = df[col].isna().sum()\n",
    "            na_pct = (na_count / len(df)) * 100\n",
    "            print(f\"  {col}: {na_count} NAs ({na_pct:.1f}%)\")\n",
    "    \n",
    "    # Check extras columns (expected to have NAs or 0s)\n",
    "    extras_cols = ['wides', 'noballs', 'byes', 'legbyes', 'penalty']\n",
    "    print(f\"\\nExtras columns (checking for NAs):\")\n",
    "    for col in extras_cols:\n",
    "        if col in df.columns:\n",
    "            na_count = df[col].isna().sum()\n",
    "            if na_count > 0:\n",
    "                print(f\"  {col}: {na_count} NAs - will be filled with 0\")\n",
    "    \n",
    "    # Check for matches with incomplete innings data\n",
    "    print(f\"\\nInnings completeness check:\")\n",
    "    innings_per_match = df.groupby('match_id')['innings'].nunique()\n",
    "    incomplete_matches = (innings_per_match < 2).sum()\n",
    "    print(f\"  Total matches: {len(innings_per_match)}\")\n",
    "    print(f\"  Matches with both innings: {(innings_per_match == 2).sum()}\")\n",
    "    print(f\"  Matches with only 1 innings: {incomplete_matches}\")\n",
    "    \n",
    "    # Check for matches with missing winner\n",
    "    print(f\"\\nWinner information:\")\n",
    "    matches_with_winner = df.groupby('match_id')['winner'].first().notna().sum()\n",
    "    total_matches = df['match_id'].nunique()\n",
    "    print(f\"  Matches with winner: {matches_with_winner}/{total_matches}\")\n",
    "    \n",
    "    # Check for matches where winner is not team1 or team2\n",
    "    match_teams = df.groupby('match_id')[['team1', 'team2', 'winner']].first()\n",
    "    winner_mismatch = ~match_teams['winner'].isin([match_teams['team1'], match_teams['team2']])\n",
    "    if winner_mismatch.sum() > 0:\n",
    "        print(f\"  ⚠ Warning: {winner_mismatch.sum()} matches where winner is neither team1 nor team2\")\n",
    "        print(f\"    (These may be ties, no results, or data errors)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    return df\n",
    "\n",
    "\n",
    "def summarize_preprocessing(processed_df):\n",
    "    \"\"\"\n",
    "    Print summary statistics of the preprocessed data.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"PREPROCESSING SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nTotal matches processed: {len(processed_df)}\")\n",
    "    print(f\"\\nTarget variable distribution:\")\n",
    "    print(f\"  Team1 wins: {processed_df['winner_binary'].sum()} ({processed_df['winner_binary'].mean()*100:.1f}%)\")\n",
    "    print(f\"  Team2 wins: {(1-processed_df['winner_binary']).sum()} ({(1-processed_df['winner_binary']).mean()*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nFeature summary:\")\n",
    "    print(f\"  Unique venues: {processed_df['venue'].nunique()}\")\n",
    "    print(f\"  Unique teams: {pd.concat([processed_df['team1'], processed_df['team2']]).nunique()}\")\n",
    "    print(f\"  Seasons covered: {processed_df['season'].nunique()}\")\n",
    "    \n",
    "    print(f\"\\nFirst 10 overs performance (mean values):\")\n",
    "    print(f\"  Team1 runs: {processed_df['team1_total_runs'].mean():.1f} (SD: {processed_df['team1_total_runs'].std():.1f})\")\n",
    "    print(f\"  Team2 runs: {processed_df['team2_total_runs'].mean():.1f} (SD: {processed_df['team2_total_runs'].std():.1f})\")\n",
    "    print(f\"  Team1 wickets: {processed_df['team1_wickets'].mean():.2f} (SD: {processed_df['team1_wickets'].std():.2f})\")\n",
    "    print(f\"  Team2 wickets: {processed_df['team2_wickets'].mean():.2f} (SD: {processed_df['team2_wickets'].std():.2f})\")\n",
    "    print(f\"  Team1 run rate: {processed_df['team1_run_rate'].mean():.2f}\")\n",
    "    print(f\"  Team2 run rate: {processed_df['team2_run_rate'].mean():.2f}\")\n",
    "    \n",
    "    print(f\"\\nRelative performance metrics (mean):\")\n",
    "    print(f\"  Runs difference: {processed_df['runs_difference'].mean():.2f}\")\n",
    "    print(f\"  Run rate difference: {processed_df['run_rate_difference'].mean():.2f}\")\n",
    "    print(f\"  Wickets difference: {processed_df['wickets_difference'].mean():.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"KEY FEATURES FOR GLMM:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nFixed Effects (potential predictors):\")\n",
    "    fixed_effects = [\n",
    "        'team1_total_runs', 'team2_total_runs', 'team1_wickets', 'team2_wickets',\n",
    "        'team1_run_rate', 'team2_run_rate', 'runs_difference', 'wickets_difference',\n",
    "        'run_rate_difference', 'team1_boundaries', 'team2_boundaries',\n",
    "        'team1_dot_ball_percentage', 'team2_dot_ball_percentage',\n",
    "        'toss_won_by_team1', 'toss_decision_bat'\n",
    "    ]\n",
    "    print(\"  \" + \"\\n  \".join(fixed_effects))\n",
    "    \n",
    "    print(\"\\nRandom Effects (grouping variables):\")\n",
    "    random_effects = ['venue', 'team1', 'team2', 'season']\n",
    "    print(\"  \" + \"\\n  \".join(random_effects))\n",
    "    \n",
    "    print(\"\\nTarget Variable:\")\n",
    "    print(\"  winner_binary (1 = team1 wins, 0 = team2 wins)\")\n",
    "    print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "000039c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA QUALITY CHECK\n",
      "================================================================================\n",
      "\n",
      "Missing values in critical columns:\n",
      "winner    16505\n",
      "dtype: int64\n",
      "\n",
      "Wicket-related columns (NAs expected when no wicket):\n",
      "  wicket_type: 603430 NAs (97.2%)\n",
      "  player_dismissed: 603430 NAs (97.2%)\n",
      "  other_wicket_type: 620646 NAs (100.0%)\n",
      "  other_player_dismissed: 620646 NAs (100.0%)\n",
      "\n",
      "Extras columns (checking for NAs):\n",
      "  wides: 606354 NAs - will be filled with 0\n",
      "  noballs: 619247 NAs - will be filled with 0\n",
      "  byes: 619645 NAs - will be filled with 0\n",
      "  legbyes: 615281 NAs - will be filled with 0\n",
      "  penalty: 620633 NAs - will be filled with 0\n",
      "\n",
      "Innings completeness check:\n",
      "  Total matches: 1173\n",
      "  Matches with both innings: 1138\n",
      "  Matches with only 1 innings: 30\n",
      "\n",
      "Winner information:\n",
      "  Matches with winner: 1118/1173\n",
      "  ⚠ Warning: 1173 matches where winner is neither team1 nor team2\n",
      "    (These may be ties, no results, or data errors)\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "PREPROCESSING SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total matches processed: 1118\n",
      "\n",
      "Target variable distribution:\n",
      "  Team1 wins: 622 (55.6%)\n",
      "  Team2 wins: 496 (44.4%)\n",
      "\n",
      "Feature summary:\n",
      "  Unique venues: 207\n",
      "  Unique teams: 22\n",
      "  Seasons covered: 24\n",
      "\n",
      "First 10 overs performance (mean values):\n",
      "  Team1 runs: 47.2 (SD: 14.4)\n",
      "  Team2 runs: 51.0 (SD: 15.9)\n",
      "  Team1 wickets: 1.38 (SD: 1.16)\n",
      "  Team2 wickets: 1.52 (SD: 1.18)\n",
      "  Team1 run rate: 4.57\n",
      "  Team2 run rate: 4.95\n",
      "\n",
      "Relative performance metrics (mean):\n",
      "  Runs difference: -3.87\n",
      "  Run rate difference: -0.38\n",
      "  Wickets difference: -0.14\n",
      "\n",
      "================================================================================\n",
      "KEY FEATURES FOR GLMM:\n",
      "================================================================================\n",
      "\n",
      "Fixed Effects (potential predictors):\n",
      "  team1_total_runs\n",
      "  team2_total_runs\n",
      "  team1_wickets\n",
      "  team2_wickets\n",
      "  team1_run_rate\n",
      "  team2_run_rate\n",
      "  runs_difference\n",
      "  wickets_difference\n",
      "  run_rate_difference\n",
      "  team1_boundaries\n",
      "  team2_boundaries\n",
      "  team1_dot_ball_percentage\n",
      "  team2_dot_ball_percentage\n",
      "  toss_won_by_team1\n",
      "  toss_decision_bat\n",
      "\n",
      "Random Effects (grouping variables):\n",
      "  venue\n",
      "  team1\n",
      "  team2\n",
      "  season\n",
      "\n",
      "Target Variable:\n",
      "  winner_binary (1 = team1 wins, 0 = team2 wins)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "    \n",
    "# Step 1: Check data quality\n",
    "check_data_quality(data)\n",
    "    \n",
    "# Step 2: Preprocess\n",
    "processed_data = preprocess_cricket_data(data)\n",
    "    \n",
    "    # Step 3: Save processed data\n",
    "#processed_data.to_csv('cricket_processed_10overs.csv', index=False)\n",
    "    \n",
    "# Step 4: Print summary\n",
    "summarize_preprocessing(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eab3e17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches after preprocessing: 1118\n",
      "Matches lost due to cleaning: 55\n"
     ]
    }
   ],
   "source": [
    "# After preprocessing\n",
    "processed = preprocess_cricket_data(data)\n",
    "print(f\"Matches after preprocessing: {len(processed)}\")\n",
    "print(f\"Matches lost due to cleaning: {data['match_id'].nunique() - len(processed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d94b033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1118, 50)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6badf612",
   "metadata": {},
   "source": [
    "# Investigating the Data to determine fixed effects and random effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9be79cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venues: 207\n",
      "Teams: 22\n",
      "Seasons: 24\n",
      "count    207.000000\n",
      "mean       5.400966\n",
      "std        6.523192\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        4.000000\n",
      "75%        6.000000\n",
      "max       59.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Number of levels\n",
    "print(f\"Venues: {processed['venue'].nunique()}\")\n",
    "print(f\"Teams: {pd.concat([processed['team1'], processed['team2']]).nunique()}\")\n",
    "print(f\"Seasons: {processed['season'].nunique()}\")\n",
    "\n",
    "# Distribution of matches per level\n",
    "print(processed['venue'].value_counts().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46a73f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation among performance metrics\n",
    "performance_cols = ['team1_total_runs', 'team2_total_runs', 'runs_difference',\n",
    "                    'team1_wickets', 'team2_wickets', 'wickets_difference',\n",
    "                    'team1_run_rate', 'team2_run_rate', 'run_rate_difference',\n",
    "                    'team1_boundaries', 'team2_boundaries']\n",
    "\n",
    "correlation_matrix = processed[performance_cols].corr()\n",
    "# Remove highly correlated pairs (|r| > 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6459bf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     team1_total_runs  team2_total_runs  runs_difference  \\\n",
      "team1_total_runs             1.000000          0.149725         0.607523   \n",
      "team2_total_runs             0.149725          1.000000        -0.694387   \n",
      "runs_difference              0.607523         -0.694387         1.000000   \n",
      "team1_wickets               -0.368536         -0.002150        -0.266495   \n",
      "team2_wickets                0.061135         -0.284996         0.273449   \n",
      "wickets_difference          -0.294450          0.196016        -0.371774   \n",
      "team1_run_rate               0.995965          0.147362         0.606484   \n",
      "team2_run_rate               0.141513          0.987768        -0.690537   \n",
      "run_rate_difference          0.601973         -0.687447         0.990385   \n",
      "team1_boundaries             0.898018          0.132282         0.547313   \n",
      "team2_boundaries             0.118189          0.911348        -0.646120   \n",
      "\n",
      "                     team1_wickets  team2_wickets  wickets_difference  \\\n",
      "team1_total_runs         -0.368536       0.061135           -0.294450   \n",
      "team2_total_runs         -0.002150      -0.284996            0.196016   \n",
      "runs_difference          -0.266495       0.273449           -0.371774   \n",
      "team1_wickets             1.000000      -0.054791            0.721990   \n",
      "team2_wickets            -0.054791       1.000000           -0.730423   \n",
      "wickets_difference        0.721990      -0.730423            1.000000   \n",
      "team1_run_rate           -0.375738       0.062638           -0.300418   \n",
      "team2_run_rate            0.012154      -0.291592            0.210371   \n",
      "run_rate_difference      -0.279740       0.279201           -0.384819   \n",
      "team1_boundaries         -0.318606       0.065823           -0.263545   \n",
      "team2_boundaries          0.025981      -0.246403            0.188515   \n",
      "\n",
      "                     team1_run_rate  team2_run_rate  run_rate_difference  \\\n",
      "team1_total_runs           0.995965        0.141513             0.601973   \n",
      "team2_total_runs           0.147362        0.987768            -0.687447   \n",
      "runs_difference            0.606484       -0.690537             0.990385   \n",
      "team1_wickets             -0.375738        0.012154            -0.279740   \n",
      "team2_wickets              0.062638       -0.291592             0.279201   \n",
      "wickets_difference        -0.300418        0.210371            -0.384819   \n",
      "team1_run_rate             1.000000        0.139789             0.606258   \n",
      "team2_run_rate             0.139789        1.000000            -0.702712   \n",
      "run_rate_difference        0.606258       -0.702712             1.000000   \n",
      "team1_boundaries           0.904032        0.124427             0.549640   \n",
      "team2_boundaries           0.114771        0.911856            -0.649895   \n",
      "\n",
      "                     team1_boundaries  team2_boundaries  \n",
      "team1_total_runs             0.898018          0.118189  \n",
      "team2_total_runs             0.132282          0.911348  \n",
      "runs_difference              0.547313         -0.646120  \n",
      "team1_wickets               -0.318606          0.025981  \n",
      "team2_wickets                0.065823         -0.246403  \n",
      "wickets_difference          -0.263545          0.188515  \n",
      "team1_run_rate               0.904032          0.114771  \n",
      "team2_run_rate               0.124427          0.911856  \n",
      "run_rate_difference          0.549640         -0.649895  \n",
      "team1_boundaries             1.000000          0.125477  \n",
      "team2_boundaries             0.125477          1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42aa5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_random_effects(df):\n",
    "    \"\"\"\n",
    "    Analyze potential random effect variables to determine suitability.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nRANDOM EFFECTS ANALYSIS\\n\")\n",
    "    \n",
    "    random_candidates = {}\n",
    "    \n",
    "    # Venue analysis\n",
    "    print(\"Venue as random effect:\")\n",
    "    n_venues = df['venue'].nunique()\n",
    "    venue_counts = df['venue'].value_counts()\n",
    "    \n",
    "    print(f\"Unique venues: {n_venues}\")\n",
    "    print(f\"Matches per venue - mean: {venue_counts.mean():.1f}, median: {venue_counts.median():.1f}, min: {venue_counts.min()}, max: {venue_counts.max()}\")\n",
    "    \n",
    "    top_5_pct = (venue_counts.head(5).sum() / len(df)) * 100\n",
    "    print(f\"Top 5 venues = {top_5_pct:.1f}% of all matches\")\n",
    "    \n",
    "    if n_venues >= 10 and venue_counts.min() >= 2:\n",
    "        print(\"Recommendation: Good candidate for random effect\")\n",
    "        recommended = True\n",
    "    elif n_venues >= 5:\n",
    "        print(\"Recommendation: Possible but limited\")\n",
    "        recommended = False\n",
    "    else:\n",
    "        print(\"Recommendation: Not enough levels\")\n",
    "        recommended = False\n",
    "    \n",
    "    random_candidates['venue'] = {\n",
    "        'n_levels': n_venues,\n",
    "        'mean_obs': venue_counts.mean(),\n",
    "        'min_obs': venue_counts.min(),\n",
    "        'recommended': recommended\n",
    "    }\n",
    "    \n",
    "    # Season analysis\n",
    "    print(\"\\nSeason as random effect:\")\n",
    "    n_seasons = df['season'].nunique()\n",
    "    season_counts = df['season'].value_counts().sort_index()\n",
    "    \n",
    "    print(f\"Unique seasons: {n_seasons}\")\n",
    "    print(f\"Matches per season - mean: {season_counts.mean():.1f}, min: {season_counts.min()}, max: {season_counts.max()}\")\n",
    "    \n",
    "    print(\"Distribution by season:\")\n",
    "    for season, count in season_counts.items():\n",
    "        print(f\"  {season}: {count} matches\")\n",
    "    \n",
    "    if n_seasons >= 6:\n",
    "        print(\"Recommendation: Good for random effect\")\n",
    "        recommended = True\n",
    "    elif n_seasons >= 4:\n",
    "        print(\"Recommendation: Consider as fixed effect instead\")\n",
    "        recommended = False\n",
    "    else:\n",
    "        print(\"Recommendation: Too few levels, use fixed\")\n",
    "        recommended = False\n",
    "    \n",
    "    random_candidates['season'] = {\n",
    "        'n_levels': n_seasons,\n",
    "        'mean_obs': season_counts.mean(),\n",
    "        'min_obs': season_counts.min(),\n",
    "        'recommended': recommended\n",
    "    }\n",
    "    \n",
    "    # Team analysis\n",
    "    print(\"\\nTeam as random effect:\")\n",
    "    \n",
    "    all_teams = pd.concat([df['team1'], df['team2']])\n",
    "    n_teams = all_teams.nunique()\n",
    "    team_counts = all_teams.value_counts()\n",
    "    \n",
    "    print(f\"Unique teams: {n_teams}\")\n",
    "    print(f\"Matches per team - mean: {team_counts.mean():.1f}, min: {team_counts.min()}, max: {team_counts.max()}\")\n",
    "    \n",
    "    print(\"\\nTop 10 teams:\")\n",
    "    for i, (team, count) in enumerate(team_counts.head(10).items(), 1):\n",
    "        print(f\"  {i}. {team}: {count} matches\")\n",
    "    \n",
    "    team1_wins = df['winner_binary'].mean()\n",
    "    print(f\"\\nTeam1 (batting first) wins {team1_wins*100:.1f}% of the time\")\n",
    "    \n",
    "    if n_teams >= 8:\n",
    "        print(\"Recommendation: Use as random effect - can do (1|team1) + (1|team2)\")\n",
    "        recommended = True\n",
    "    else:\n",
    "        print(\"Recommendation: Maybe use as fixed effect\")\n",
    "        recommended = False\n",
    "    \n",
    "    random_candidates['team'] = {\n",
    "        'n_levels': n_teams,\n",
    "        'mean_obs': team_counts.mean(),\n",
    "        'min_obs': team_counts.min(),\n",
    "        'recommended': recommended\n",
    "    }\n",
    "    \n",
    "    return random_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9eeff840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def analyze_fixed_effects(df, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Analyze fixed effect candidates and check for multicollinearity.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\\nFIXED EFFECTS ANALYSIS\\n\")\n",
    "    \n",
    "    # Get performance metrics\n",
    "    performance_metrics = [\n",
    "        'team1_total_runs', 'team2_total_runs', 'runs_difference',\n",
    "        'team1_wickets', 'team2_wickets', 'wickets_difference',\n",
    "        'team1_run_rate', 'team2_run_rate', 'run_rate_difference',\n",
    "        'team1_boundaries', 'team2_boundaries', 'boundary_difference',\n",
    "        'team1_dot_ball_percentage', 'team2_dot_ball_percentage',\n",
    "        'team1_fours', 'team2_fours', 'team1_sixes', 'team2_sixes',\n",
    "        'team1_total_extras', 'team2_total_extras'\n",
    "    ]\n",
    "    \n",
    "    available_metrics = [col for col in performance_metrics if col in df.columns]\n",
    "    \n",
    "    toss_variables = ['toss_won_by_team1', 'toss_decision_bat']\n",
    "    available_metrics.extend([col for col in toss_variables if col in df.columns])\n",
    "    \n",
    "    print(f\"Available metrics: {len(available_metrics)}\")\n",
    "    \n",
    "    # Correlation matrix\n",
    "    correlation_matrix = df[available_metrics].corr()\n",
    "    \n",
    "    print(f\"\\nHighly correlated pairs (|r| > {threshold}):\")\n",
    "    \n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_value = correlation_matrix.iloc[i, j]\n",
    "            if abs(corr_value) > threshold:\n",
    "                var1 = correlation_matrix.columns[i]\n",
    "                var2 = correlation_matrix.columns[j]\n",
    "                high_corr_pairs.append({\n",
    "                    'var1': var1,\n",
    "                    'var2': var2,\n",
    "                    'correlation': corr_value\n",
    "                })\n",
    "                print(f\"  {var1} <-> {var2}: r = {corr_value:.3f}\")\n",
    "    \n",
    "    if not high_corr_pairs:\n",
    "        print(\"  None found\")\n",
    "    \n",
    "    # Correlation with outcome\n",
    "    print(\"\\nCorrelation with winner (top 15):\")\n",
    "    \n",
    "    target_correlations = df[available_metrics].corrwith(df['winner_binary']).abs().sort_values(ascending=False)\n",
    "    \n",
    "    for i, (var, corr) in enumerate(target_correlations.head(15).items(), 1):\n",
    "        print(f\"  {i}. {var}: |r| = {corr:.3f}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(\"\\n\\nRECOMMENDATIONS:\\n\")\n",
    "    \n",
    "    print(\"Strategy 1 - Use difference metrics (simplest):\")\n",
    "    strategy1_vars = [\n",
    "        'runs_difference',\n",
    "        'wickets_difference', \n",
    "        'run_rate_difference',\n",
    "        'boundary_difference',\n",
    "        'team1_dot_ball_percentage',\n",
    "        'team2_dot_ball_percentage',\n",
    "        'toss_won_by_team1',\n",
    "        'toss_decision_bat'\n",
    "    ]\n",
    "    strategy1_available = [v for v in strategy1_vars if v in df.columns]\n",
    "    print(f\"  Variables: {', '.join(strategy1_available)}\")\n",
    "    print(f\"  Total: {len(strategy1_available)} predictors\")\n",
    "    \n",
    "    print(\"\\nStrategy 2 - Use individual team metrics:\")\n",
    "    strategy2_vars = [\n",
    "        'team1_total_runs',\n",
    "        'team2_total_runs',\n",
    "        'team1_wickets',\n",
    "        'team2_wickets',\n",
    "        'team1_boundaries',\n",
    "        'team2_boundaries',\n",
    "        'team1_dot_ball_percentage',\n",
    "        'team2_dot_ball_percentage',\n",
    "        'toss_won_by_team1',\n",
    "        'toss_decision_bat'\n",
    "    ]\n",
    "    strategy2_available = [v for v in strategy2_vars if v in df.columns]\n",
    "    print(f\"  Variables: {', '.join(strategy2_available)}\")\n",
    "    print(f\"  Total: {len(strategy2_available)} predictors\")\n",
    "    \n",
    "    print(\"\\nStrategy 3 - Hybrid (recommended to start):\")\n",
    "    strategy3_vars = [\n",
    "        'runs_difference',\n",
    "        'team1_wickets',\n",
    "        'team2_wickets',\n",
    "        'team1_run_rate',\n",
    "        'team2_run_rate',\n",
    "        'boundary_difference',\n",
    "        'team1_dot_ball_percentage',\n",
    "        'toss_won_by_team1',\n",
    "        'toss_decision_bat'\n",
    "    ]\n",
    "    strategy3_available = [v for v in strategy3_vars if v in df.columns]\n",
    "    print(f\"  Variables: {', '.join(strategy3_available)}\")\n",
    "    print(f\"  Total: {len(strategy3_available)} predictors\")\n",
    "    \n",
    "    print(\"\\nMaking correlation heatmap...\")\n",
    "    \n",
    "    return {\n",
    "        'correlation_matrix': correlation_matrix,\n",
    "        'high_corr_pairs': high_corr_pairs,\n",
    "        'target_correlations': target_correlations,\n",
    "        'strategy1': strategy1_available,\n",
    "        'strategy2': strategy2_available,\n",
    "        'strategy3': strategy3_available\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "189357d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_correlation_heatmap(correlation_matrix, figsize=(14, 12)):\n",
    "    \"\"\"\n",
    "    Create correlation heatmap.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    \n",
    "    sns.heatmap(correlation_matrix, \n",
    "                mask=mask,\n",
    "                annot=True, \n",
    "                fmt='.2f', \n",
    "                cmap='coolwarm', \n",
    "                center=0,\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                cbar_kws={\"shrink\": 0.8})\n",
    "    \n",
    "    plt.title('Correlation Matrix', fontsize=16, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Saved as correlation_heatmap.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "123cac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def examine_random_effect_variance(df, random_effect_var, outcome='winner_binary'):\n",
    "    \"\"\"\n",
    "    Check if random effect shows meaningful variance.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n\\nChecking variance for {random_effect_var}:\\n\")\n",
    "    \n",
    "    group_stats = df.groupby(random_effect_var).agg({\n",
    "        outcome: ['mean', 'count']\n",
    "    }).round(3)\n",
    "    \n",
    "    group_stats.columns = ['win_rate', 'n_matches']\n",
    "    group_stats = group_stats.sort_values('win_rate', ascending=False)\n",
    "    \n",
    "    overall_mean = df[outcome].mean()\n",
    "    group_variance = group_stats['win_rate'].var()\n",
    "    \n",
    "    print(f\"Overall team1 win rate: {overall_mean:.3f}\")\n",
    "    print(f\"Variance across {random_effect_var}: {group_variance:.6f}\")\n",
    "    print(f\"SD: {np.sqrt(group_variance):.3f}\")\n",
    "    \n",
    "    print(f\"\\nTop 10 {random_effect_var}:\")\n",
    "    print(group_stats.head(10))\n",
    "    \n",
    "    print(f\"\\nBottom 10 {random_effect_var}:\")\n",
    "    print(group_stats.tail(10))\n",
    "    \n",
    "    if group_variance > 0.01:\n",
    "        print(f\"\\nLooks like {random_effect_var} has substantial variance, should use as random effect\")\n",
    "    else:\n",
    "        print(f\"\\nNot much variance in {random_effect_var}, might not help much\")\n",
    "    \n",
    "    return group_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca4cefeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_model_recommendations(random_candidates, fixed_analysis):\n",
    "    \"\"\"\n",
    "    Generate final recommendations.\n",
    "    \"\"\"\n",
    "    print(\"\\n\\nFINAL RECOMMENDATIONS\\n\")\n",
    "    \n",
    "    print(\"Random effects:\")\n",
    "    random_effects_formula = []\n",
    "    if random_candidates['venue']['recommended']:\n",
    "        random_effects_formula.append(\"(1 | venue)\")\n",
    "    if random_candidates['season']['recommended']:\n",
    "        random_effects_formula.append(\"(1 | season)\")\n",
    "    if random_candidates['team']['recommended']:\n",
    "        random_effects_formula.append(\"(1 | team1) + (1 | team2)\")\n",
    "    \n",
    "    if random_effects_formula:\n",
    "        print(\"  \" + \" + \".join(random_effects_formula))\n",
    "    else:\n",
    "        print(\"  None recommended - might just use regular logistic regression\")\n",
    "    \n",
    "    print(\"\\nSuggested models to try:\")\n",
    "    print(\"\\nModel 1 (simple baseline):\")\n",
    "    print(\"  winner_binary ~ runs_difference + wickets_difference + toss_won_by_team1\")\n",
    "    \n",
    "    print(\"\\nModel 2 (extended):\")\n",
    "    print(\"  winner_binary ~ runs_difference + wickets_difference + boundary_difference +\")\n",
    "    print(\"                  team1_dot_ball_percentage + toss_won_by_team1 + toss_decision_bat\")\n",
    "    \n",
    "    print(\"\\nModel 3 (hybrid approach):\")\n",
    "    fixed_vars = \" + \".join(fixed_analysis['strategy3'][:6])\n",
    "    print(f\"  winner_binary ~ {fixed_vars} + ...\")\n",
    "    \n",
    "    print(\"\\n\\nNext steps:\")\n",
    "    print(\"- Start with model 1\")\n",
    "    print(\"- Fit with statsmodels or R\")\n",
    "    print(\"- Compare AIC/BIC\")\n",
    "    print(\"- Check random effect variance components\")\n",
    "    print(\"- Do some cross-validation\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "474755cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_glmm_structure(df):\n",
    "    \"\"\"\n",
    "    Run full GLMM structure analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nGLMM STRUCTURE ANALYSIS\")\n",
    "    print(\"Analyzing random and fixed effects for cricket match prediction\\n\")\n",
    "    \n",
    "    # Analyze random effects\n",
    "    random_candidates = analyze_random_effects(df)\n",
    "    \n",
    "    # Analyze fixed effects\n",
    "    fixed_analysis = analyze_fixed_effects(df)\n",
    "    \n",
    "    # Make heatmap\n",
    "    plot_correlation_heatmap(fixed_analysis['correlation_matrix'])\n",
    "    \n",
    "    # Check variance in random effects\n",
    "    for effect in ['venue', 'season']:\n",
    "        if effect in df.columns and random_candidates[effect]['recommended']:\n",
    "            examine_random_effect_variance(df, effect)\n",
    "    \n",
    "    # Final recommendations\n",
    "    generate_model_recommendations(random_candidates, fixed_analysis)\n",
    "    \n",
    "    return {\n",
    "        'random_candidates': random_candidates,\n",
    "        'fixed_analysis': fixed_analysis\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "760022e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to analyze GLMM structure\n",
      "Run: results = analyze_glmm_structure(processed_data)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_random_effects(df):\n",
    "    \"\"\"\n",
    "    Analyze potential random effect variables to determine suitability.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nRANDOM EFFECTS ANALYSIS\\n\")\n",
    "    \n",
    "    random_candidates = {}\n",
    "    \n",
    "    # Venue analysis\n",
    "    print(\"Venue as random effect:\")\n",
    "    n_venues = df['venue'].nunique()\n",
    "    venue_counts = df['venue'].value_counts()\n",
    "    \n",
    "    print(f\"Unique venues: {n_venues}\")\n",
    "    print(f\"Matches per venue - mean: {venue_counts.mean():.1f}, median: {venue_counts.median():.1f}, min: {venue_counts.min()}, max: {venue_counts.max()}\")\n",
    "    \n",
    "    top_5_pct = (venue_counts.head(5).sum() / len(df)) * 100\n",
    "    print(f\"Top 5 venues = {top_5_pct:.1f}% of all matches\")\n",
    "    \n",
    "    if n_venues >= 10 and venue_counts.min() >= 2:\n",
    "        print(\"Recommendation: Good candidate for random effect\")\n",
    "        recommended = True\n",
    "    elif n_venues >= 5:\n",
    "        print(\"Recommendation: Possible but limited\")\n",
    "        recommended = False\n",
    "    else:\n",
    "        print(\"Recommendation: Not enough levels\")\n",
    "        recommended = False\n",
    "    \n",
    "    random_candidates['venue'] = {\n",
    "        'n_levels': n_venues,\n",
    "        'mean_obs': venue_counts.mean(),\n",
    "        'min_obs': venue_counts.min(),\n",
    "        'recommended': recommended\n",
    "    }\n",
    "    \n",
    "    # Season analysis\n",
    "    print(\"\\nSeason as random effect:\")\n",
    "    n_seasons = df['season'].nunique()\n",
    "    \n",
    "    # Convert season to string to avoid mixed type issues, then sort\n",
    "    season_counts = df['season'].astype(str).value_counts()\n",
    "    try:\n",
    "        season_counts = season_counts.sort_index()\n",
    "    except:\n",
    "        # If sorting fails, just use unsorted\n",
    "        pass\n",
    "    \n",
    "    print(f\"Unique seasons: {n_seasons}\")\n",
    "    print(f\"Matches per season - mean: {season_counts.mean():.1f}, min: {season_counts.min()}, max: {season_counts.max()}\")\n",
    "    \n",
    "    print(\"Distribution by season:\")\n",
    "    for season, count in season_counts.items():\n",
    "        print(f\"  {season}: {count} matches\")\n",
    "    \n",
    "    if n_seasons >= 6:\n",
    "        print(\"Recommendation: Good for random effect\")\n",
    "        recommended = True\n",
    "    elif n_seasons >= 4:\n",
    "        print(\"Recommendation: Consider as fixed effect instead\")\n",
    "        recommended = False\n",
    "    else:\n",
    "        print(\"Recommendation: Too few levels, use fixed\")\n",
    "        recommended = False\n",
    "    \n",
    "    random_candidates['season'] = {\n",
    "        'n_levels': n_seasons,\n",
    "        'mean_obs': season_counts.mean(),\n",
    "        'min_obs': season_counts.min(),\n",
    "        'recommended': recommended\n",
    "    }\n",
    "    \n",
    "    # Team analysis\n",
    "    print(\"\\nTeam as random effect:\")\n",
    "    \n",
    "    all_teams = pd.concat([df['team1'], df['team2']])\n",
    "    n_teams = all_teams.nunique()\n",
    "    team_counts = all_teams.value_counts()\n",
    "    \n",
    "    print(f\"Unique teams: {n_teams}\")\n",
    "    print(f\"Matches per team - mean: {team_counts.mean():.1f}, min: {team_counts.min()}, max: {team_counts.max()}\")\n",
    "    \n",
    "    print(\"\\nTop 10 teams:\")\n",
    "    for i, (team, count) in enumerate(team_counts.head(10).items(), 1):\n",
    "        print(f\"  {i}. {team}: {count} matches\")\n",
    "    \n",
    "    team1_wins = df['winner_binary'].mean()\n",
    "    print(f\"\\nTeam1 (batting first) wins {team1_wins*100:.1f}% of the time\")\n",
    "    \n",
    "    if n_teams >= 8:\n",
    "        print(\"Recommendation: Use as random effect - can do (1|team1) + (1|team2)\")\n",
    "        recommended = True\n",
    "    else:\n",
    "        print(\"Recommendation: Maybe use as fixed effect\")\n",
    "        recommended = False\n",
    "    \n",
    "    random_candidates['team'] = {\n",
    "        'n_levels': n_teams,\n",
    "        'mean_obs': team_counts.mean(),\n",
    "        'min_obs': team_counts.min(),\n",
    "        'recommended': recommended\n",
    "    }\n",
    "    \n",
    "    return random_candidates\n",
    "\n",
    "\n",
    "def analyze_fixed_effects(df, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Analyze fixed effect candidates and check for multicollinearity.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\\nFIXED EFFECTS ANALYSIS\\n\")\n",
    "    \n",
    "    # Get performance metrics\n",
    "    performance_metrics = [\n",
    "        'team1_total_runs', 'team2_total_runs', 'runs_difference',\n",
    "        'team1_wickets', 'team2_wickets', 'wickets_difference',\n",
    "        'team1_run_rate', 'team2_run_rate', 'run_rate_difference',\n",
    "        'team1_boundaries', 'team2_boundaries', 'boundary_difference',\n",
    "        'team1_dot_ball_percentage', 'team2_dot_ball_percentage',\n",
    "        'team1_fours', 'team2_fours', 'team1_sixes', 'team2_sixes',\n",
    "        'team1_total_extras', 'team2_total_extras'\n",
    "    ]\n",
    "    \n",
    "    available_metrics = [col for col in performance_metrics if col in df.columns]\n",
    "    \n",
    "    toss_variables = ['toss_won_by_team1', 'toss_decision_bat']\n",
    "    available_metrics.extend([col for col in toss_variables if col in df.columns])\n",
    "    \n",
    "    print(f\"Available metrics: {len(available_metrics)}\")\n",
    "    \n",
    "    # Correlation matrix\n",
    "    correlation_matrix = df[available_metrics].corr()\n",
    "    \n",
    "    print(f\"\\nHighly correlated pairs (|r| > {threshold}):\")\n",
    "    \n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_value = correlation_matrix.iloc[i, j]\n",
    "            if abs(corr_value) > threshold:\n",
    "                var1 = correlation_matrix.columns[i]\n",
    "                var2 = correlation_matrix.columns[j]\n",
    "                high_corr_pairs.append({\n",
    "                    'var1': var1,\n",
    "                    'var2': var2,\n",
    "                    'correlation': corr_value\n",
    "                })\n",
    "                print(f\"  {var1} <-> {var2}: r = {corr_value:.3f}\")\n",
    "    \n",
    "    if not high_corr_pairs:\n",
    "        print(\"  None found\")\n",
    "    \n",
    "    # Correlation with outcome\n",
    "    print(\"\\nCorrelation with winner (top 15):\")\n",
    "    \n",
    "    target_correlations = df[available_metrics].corrwith(df['winner_binary']).abs().sort_values(ascending=False)\n",
    "    \n",
    "    for i, (var, corr) in enumerate(target_correlations.head(15).items(), 1):\n",
    "        print(f\"  {i}. {var}: |r| = {corr:.3f}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(\"\\n\\nRECOMMENDATIONS:\\n\")\n",
    "    \n",
    "    print(\"Strategy 1 - Use difference metrics (simplest):\")\n",
    "    strategy1_vars = [\n",
    "        'runs_difference',\n",
    "        'wickets_difference', \n",
    "        'run_rate_difference',\n",
    "        'boundary_difference',\n",
    "        'team1_dot_ball_percentage',\n",
    "        'team2_dot_ball_percentage',\n",
    "        'toss_won_by_team1',\n",
    "        'toss_decision_bat'\n",
    "    ]\n",
    "    strategy1_available = [v for v in strategy1_vars if v in df.columns]\n",
    "    print(f\"  Variables: {', '.join(strategy1_available)}\")\n",
    "    print(f\"  Total: {len(strategy1_available)} predictors\")\n",
    "    \n",
    "    print(\"\\nStrategy 2 - Use individual team metrics:\")\n",
    "    strategy2_vars = [\n",
    "        'team1_total_runs',\n",
    "        'team2_total_runs',\n",
    "        'team1_wickets',\n",
    "        'team2_wickets',\n",
    "        'team1_boundaries',\n",
    "        'team2_boundaries',\n",
    "        'team1_dot_ball_percentage',\n",
    "        'team2_dot_ball_percentage',\n",
    "        'toss_won_by_team1',\n",
    "        'toss_decision_bat'\n",
    "    ]\n",
    "    strategy2_available = [v for v in strategy2_vars if v in df.columns]\n",
    "    print(f\"  Variables: {', '.join(strategy2_available)}\")\n",
    "    print(f\"  Total: {len(strategy2_available)} predictors\")\n",
    "    \n",
    "    print(\"\\nStrategy 3 - Hybrid (recommended to start):\")\n",
    "    strategy3_vars = [\n",
    "        'runs_difference',\n",
    "        'team1_wickets',\n",
    "        'team2_wickets',\n",
    "        'team1_run_rate',\n",
    "        'team2_run_rate',\n",
    "        'boundary_difference',\n",
    "        'team1_dot_ball_percentage',\n",
    "        'toss_won_by_team1',\n",
    "        'toss_decision_bat'\n",
    "    ]\n",
    "    strategy3_available = [v for v in strategy3_vars if v in df.columns]\n",
    "    print(f\"  Variables: {', '.join(strategy3_available)}\")\n",
    "    print(f\"  Total: {len(strategy3_available)} predictors\")\n",
    "    \n",
    "    print(\"\\nMaking correlation heatmap...\")\n",
    "    \n",
    "    return {\n",
    "        'correlation_matrix': correlation_matrix,\n",
    "        'high_corr_pairs': high_corr_pairs,\n",
    "        'target_correlations': target_correlations,\n",
    "        'strategy1': strategy1_available,\n",
    "        'strategy2': strategy2_available,\n",
    "        'strategy3': strategy3_available\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_correlation_heatmap(correlation_matrix, figsize=(14, 12)):\n",
    "    \"\"\"\n",
    "    Create correlation heatmap.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    \n",
    "    sns.heatmap(correlation_matrix, \n",
    "                mask=mask,\n",
    "                annot=True, \n",
    "                fmt='.2f', \n",
    "                cmap='coolwarm', \n",
    "                center=0,\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                cbar_kws={\"shrink\": 0.8})\n",
    "    \n",
    "    plt.title('Correlation Matrix', fontsize=16, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Saved as correlation_heatmap.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def examine_random_effect_variance(df, random_effect_var, outcome='winner_binary'):\n",
    "    \"\"\"\n",
    "    Check if random effect shows meaningful variance.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n\\nChecking variance for {random_effect_var}:\\n\")\n",
    "    \n",
    "    group_stats = df.groupby(random_effect_var).agg({\n",
    "        outcome: ['mean', 'count']\n",
    "    }).round(3)\n",
    "    \n",
    "    group_stats.columns = ['win_rate', 'n_matches']\n",
    "    group_stats = group_stats.sort_values('win_rate', ascending=False)\n",
    "    \n",
    "    overall_mean = df[outcome].mean()\n",
    "    group_variance = group_stats['win_rate'].var()\n",
    "    \n",
    "    print(f\"Overall team1 win rate: {overall_mean:.3f}\")\n",
    "    print(f\"Variance across {random_effect_var}: {group_variance:.6f}\")\n",
    "    print(f\"SD: {np.sqrt(group_variance):.3f}\")\n",
    "    \n",
    "    print(f\"\\nTop 10 {random_effect_var}:\")\n",
    "    print(group_stats.head(10))\n",
    "    \n",
    "    print(f\"\\nBottom 10 {random_effect_var}:\")\n",
    "    print(group_stats.tail(10))\n",
    "    \n",
    "    if group_variance > 0.01:\n",
    "        print(f\"\\nLooks like {random_effect_var} has substantial variance, should use as random effect\")\n",
    "    else:\n",
    "        print(f\"\\nNot much variance in {random_effect_var}, might not help much\")\n",
    "    \n",
    "    return group_stats\n",
    "\n",
    "\n",
    "def generate_model_recommendations(random_candidates, fixed_analysis):\n",
    "    \"\"\"\n",
    "    Generate final recommendations.\n",
    "    \"\"\"\n",
    "    print(\"\\n\\nFINAL RECOMMENDATIONS\\n\")\n",
    "    \n",
    "    print(\"Random effects:\")\n",
    "    random_effects_formula = []\n",
    "    if random_candidates['venue']['recommended']:\n",
    "        random_effects_formula.append(\"(1 | venue)\")\n",
    "    if random_candidates['season']['recommended']:\n",
    "        random_effects_formula.append(\"(1 | season)\")\n",
    "    if random_candidates['team']['recommended']:\n",
    "        random_effects_formula.append(\"(1 | team1) + (1 | team2)\")\n",
    "    \n",
    "    if random_effects_formula:\n",
    "        print(\"  \" + \" + \".join(random_effects_formula))\n",
    "    else:\n",
    "        print(\"  None recommended - might just use regular logistic regression\")\n",
    "    \n",
    "    print(\"\\nSuggested models to try:\")\n",
    "    print(\"\\nModel 1 (simple baseline):\")\n",
    "    print(\"  winner_binary ~ runs_difference + wickets_difference + toss_won_by_team1\")\n",
    "    \n",
    "    print(\"\\nModel 2 (extended):\")\n",
    "    print(\"  winner_binary ~ runs_difference + wickets_difference + boundary_difference +\")\n",
    "    print(\"                  team1_dot_ball_percentage + toss_won_by_team1 + toss_decision_bat\")\n",
    "    \n",
    "    print(\"\\nModel 3 (hybrid approach):\")\n",
    "    fixed_vars = \" + \".join(fixed_analysis['strategy3'][:6])\n",
    "    print(f\"  winner_binary ~ {fixed_vars} + ...\")\n",
    "    \n",
    "    print(\"\\n\\nNext steps:\")\n",
    "    print(\"- Start with model 1\")\n",
    "    print(\"- Fit with statsmodels or R\")\n",
    "    print(\"- Compare AIC/BIC\")\n",
    "    print(\"- Check random effect variance components\")\n",
    "    print(\"- Do some cross-validation\")\n",
    "\n",
    "\n",
    "def analyze_glmm_structure(df):\n",
    "    \"\"\"\n",
    "    Run full GLMM structure analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nGLMM STRUCTURE ANALYSIS\")\n",
    "    print(\"Analyzing random and fixed effects for cricket match prediction\\n\")\n",
    "    \n",
    "    # Analyze random effects\n",
    "    random_candidates = analyze_random_effects(df)\n",
    "    \n",
    "    # Analyze fixed effects\n",
    "    fixed_analysis = analyze_fixed_effects(df)\n",
    "    \n",
    "    # Make heatmap\n",
    "    plot_correlation_heatmap(fixed_analysis['correlation_matrix'])\n",
    "    \n",
    "    # Check variance in random effects\n",
    "    for effect in ['venue', 'season']:\n",
    "        if effect in df.columns and random_candidates[effect]['recommended']:\n",
    "            examine_random_effect_variance(df, effect)\n",
    "    \n",
    "    # Final recommendations\n",
    "    generate_model_recommendations(random_candidates, fixed_analysis)\n",
    "    \n",
    "    return {\n",
    "        'random_candidates': random_candidates,\n",
    "        'fixed_analysis': fixed_analysis\n",
    "    }\n",
    "\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # After preprocessing:\n",
    "    # results = analyze_glmm_structure(processed_data)\n",
    "    \n",
    "    print(\"Ready to analyze GLMM structure\")\n",
    "    print(\"Run: results = analyze_glmm_structure(processed_data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f18cb5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GLMM STRUCTURE ANALYSIS\n",
      "Analyzing random and fixed effects for cricket match prediction\n",
      "\n",
      "\n",
      "RANDOM EFFECTS ANALYSIS\n",
      "\n",
      "Venue as random effect:\n",
      "Unique venues: 207\n",
      "Matches per venue - mean: 5.4, median: 4.0, min: 1, max: 59\n",
      "Top 5 venues = 15.9% of all matches\n",
      "Recommendation: Possible but limited\n",
      "\n",
      "Season as random effect:\n",
      "Unique seasons: 24\n",
      "Matches per season - mean: 50.8, min: 6, max: 80\n",
      "Distribution by season:\n",
      "  2014/15: 62 matches\n",
      "  2015: 36 matches\n",
      "  2015/16: 41 matches\n",
      "  2016: 30 matches\n",
      "  2016/17: 62 matches\n",
      "  2017: 48 matches\n",
      "  2017/18: 72 matches\n",
      "  2018: 30 matches\n",
      "  2018/19: 63 matches\n",
      "  2019: 72 matches\n",
      "  2019/20: 41 matches\n",
      "  2020: 6 matches\n",
      "  2020/21: 19 matches\n",
      "  2021: 45 matches\n",
      "  2021/22: 39 matches\n",
      "  2022: 79 matches\n",
      "  2022/23: 74 matches\n",
      "  2023: 79 matches\n",
      "  2023/24: 80 matches\n",
      "  2024: 29 matches\n",
      "  2024/25: 70 matches\n",
      "  2025: 41 matches\n",
      "Recommendation: Good for random effect\n",
      "\n",
      "Team as random effect:\n",
      "Unique teams: 22\n",
      "Matches per team - mean: 101.6, min: 4, max: 187\n",
      "\n",
      "Top 10 teams:\n",
      "  1. India: 187 matches\n",
      "  2. Sri Lanka: 173 matches\n",
      "  3. England: 167 matches\n",
      "  4. New Zealand: 165 matches\n",
      "  5. Australia: 165 matches\n",
      "  6. South Africa: 157 matches\n",
      "  7. West Indies: 154 matches\n",
      "  8. Pakistan: 151 matches\n",
      "  9. Bangladesh: 131 matches\n",
      "  10. Zimbabwe: 109 matches\n",
      "\n",
      "Team1 (batting first) wins 55.6% of the time\n",
      "Recommendation: Use as random effect - can do (1|team1) + (1|team2)\n",
      "\n",
      "\n",
      "FIXED EFFECTS ANALYSIS\n",
      "\n",
      "Available metrics: 22\n",
      "\n",
      "Highly correlated pairs (|r| > 0.8):\n",
      "  team1_total_runs <-> team1_run_rate: r = 0.996\n",
      "  team1_total_runs <-> team1_boundaries: r = 0.898\n",
      "  team1_total_runs <-> team1_dot_ball_percentage: r = -0.834\n",
      "  team1_total_runs <-> team1_fours: r = 0.813\n",
      "  team2_total_runs <-> team2_run_rate: r = 0.988\n",
      "  team2_total_runs <-> team2_boundaries: r = 0.911\n",
      "  team2_total_runs <-> team2_dot_ball_percentage: r = -0.840\n",
      "  runs_difference <-> run_rate_difference: r = 0.990\n",
      "  runs_difference <-> boundary_difference: r = 0.904\n",
      "  team1_run_rate <-> team1_boundaries: r = 0.904\n",
      "  team1_run_rate <-> team1_dot_ball_percentage: r = -0.827\n",
      "  team1_run_rate <-> team1_fours: r = 0.819\n",
      "  team2_run_rate <-> team2_boundaries: r = 0.912\n",
      "  team2_run_rate <-> team2_dot_ball_percentage: r = -0.834\n",
      "  run_rate_difference <-> boundary_difference: r = 0.909\n",
      "  team1_boundaries <-> team1_fours: r = 0.949\n",
      "  team2_boundaries <-> team2_fours: r = 0.930\n",
      "\n",
      "Correlation with winner (top 15):\n",
      "  1. wickets_difference: |r| = 0.281\n",
      "  2. team2_wickets: |r| = 0.213\n",
      "  3. team1_wickets: |r| = 0.195\n",
      "  4. run_rate_difference: |r| = 0.190\n",
      "  5. runs_difference: |r| = 0.189\n",
      "  6. boundary_difference: |r| = 0.183\n",
      "  7. team1_total_runs: |r| = 0.162\n",
      "  8. team1_run_rate: |r| = 0.162\n",
      "  9. team1_dot_ball_percentage: |r| = 0.161\n",
      "  10. team1_boundaries: |r| = 0.131\n",
      "  11. team2_boundaries: |r| = 0.113\n",
      "  12. team1_fours: |r| = 0.112\n",
      "  13. team2_fours: |r| = 0.108\n",
      "  14. team1_sixes: |r| = 0.095\n",
      "  15. team2_run_rate: |r| = 0.091\n",
      "\n",
      "\n",
      "RECOMMENDATIONS:\n",
      "\n",
      "Strategy 1 - Use difference metrics (simplest):\n",
      "  Variables: runs_difference, wickets_difference, run_rate_difference, boundary_difference, team1_dot_ball_percentage, team2_dot_ball_percentage, toss_won_by_team1, toss_decision_bat\n",
      "  Total: 8 predictors\n",
      "\n",
      "Strategy 2 - Use individual team metrics:\n",
      "  Variables: team1_total_runs, team2_total_runs, team1_wickets, team2_wickets, team1_boundaries, team2_boundaries, team1_dot_ball_percentage, team2_dot_ball_percentage, toss_won_by_team1, toss_decision_bat\n",
      "  Total: 10 predictors\n",
      "\n",
      "Strategy 3 - Hybrid (recommended to start):\n",
      "  Variables: runs_difference, team1_wickets, team2_wickets, team1_run_rate, team2_run_rate, boundary_difference, team1_dot_ball_percentage, toss_won_by_team1, toss_decision_bat\n",
      "  Total: 9 predictors\n",
      "\n",
      "Making correlation heatmap...\n",
      "Saved as correlation_heatmap.png\n",
      "\n",
      "\n",
      "Checking variance for season:\n",
      "\n",
      "Overall team1 win rate: 0.556\n",
      "Variance across season: 0.015894\n",
      "SD: 0.126\n",
      "\n",
      "Top 10 season:\n",
      "         win_rate  n_matches\n",
      "season                      \n",
      "2014/15     0.806         62\n",
      "2019        0.775         40\n",
      "2019/20     0.732         41\n",
      "2016/17     0.694         62\n",
      "2015/16     0.683         41\n",
      "2019        0.656         32\n",
      "2025        0.634         41\n",
      "2020/21     0.632         19\n",
      "2018/19     0.587         63\n",
      "2023        0.557         79\n",
      "\n",
      "Bottom 10 season:\n",
      "         win_rate  n_matches\n",
      "season                      \n",
      "2016        0.500         30\n",
      "2021/22     0.487         39\n",
      "2024        0.483         29\n",
      "2022        0.481         79\n",
      "2024/25     0.457         70\n",
      "2021        0.444         45\n",
      "2022/23     0.432         74\n",
      "2023/24     0.412         80\n",
      "2017        0.364         22\n",
      "2020        0.333          6\n",
      "\n",
      "Looks like season has substantial variance, should use as random effect\n",
      "\n",
      "\n",
      "FINAL RECOMMENDATIONS\n",
      "\n",
      "Random effects:\n",
      "  (1 | season) + (1 | team1) + (1 | team2)\n",
      "\n",
      "Suggested models to try:\n",
      "\n",
      "Model 1 (simple baseline):\n",
      "  winner_binary ~ runs_difference + wickets_difference + toss_won_by_team1\n",
      "\n",
      "Model 2 (extended):\n",
      "  winner_binary ~ runs_difference + wickets_difference + boundary_difference +\n",
      "                  team1_dot_ball_percentage + toss_won_by_team1 + toss_decision_bat\n",
      "\n",
      "Model 3 (hybrid approach):\n",
      "  winner_binary ~ runs_difference + team1_wickets + team2_wickets + team1_run_rate + team2_run_rate + boundary_difference + ...\n",
      "\n",
      "\n",
      "Next steps:\n",
      "- Start with model 1\n",
      "- Fit with statsmodels or R\n",
      "- Compare AIC/BIC\n",
      "- Check random effect variance components\n",
      "- Do some cross-validation\n"
     ]
    }
   ],
   "source": [
    "results = analyze_glmm_structure(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2b772c",
   "metadata": {},
   "source": [
    "## Selected Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5345c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns = [\n",
    "        # Outcome\n",
    "        'winner_binary',\n",
    "        \n",
    "        # Random effects\n",
    "        'season',\n",
    "        'team1',\n",
    "        'team2',\n",
    "        \n",
    "        # Fixed effects - difference metrics (avoiding multicollinearity)\n",
    "        'runs_difference',\n",
    "        'wickets_difference',\n",
    "        'boundary_difference',\n",
    "        \n",
    "        # Fixed effects - individual team metrics\n",
    "        'team1_wickets',\n",
    "        'team2_wickets',\n",
    "        'team1_dot_ball_percentage',\n",
    "        'team2_dot_ball_percentage',\n",
    "        \n",
    "        # Toss variables\n",
    "        'toss_won_by_team1',\n",
    "        'toss_decision_bat',\n",
    "        \n",
    "        # Keep match_id for reference\n",
    "        'match_id'\n",
    "    ]\n",
    "\n",
    "# Create modeling dataset\n",
    "modeling_data = processed_data[model_columns].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "592a03c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   winner_binary   season         team1        team2  runs_difference  \\\n",
      "0              1  2014/15   New Zealand    Sri Lanka               31   \n",
      "1              1  2014/15     Australia      England               16   \n",
      "2              1  2014/15  South Africa     Zimbabwe              -28   \n",
      "3              1  2014/15         India     Pakistan               -4   \n",
      "4              1  2014/15       Ireland  West Indies              -21   \n",
      "\n",
      "   wickets_difference  boundary_difference  team1_wickets  team2_wickets  \\\n",
      "0                   0                    4              0              0   \n",
      "1                   0                    0              2              2   \n",
      "2                   1                   -5              2              1   \n",
      "3                   0                    0              1              1   \n",
      "4                   2                   -1              2              0   \n",
      "\n",
      "   team1_dot_ball_percentage  team2_dot_ball_percentage  toss_won_by_team1  \\\n",
      "0                  48.437500                  63.333333                  0   \n",
      "1                  51.612903                  59.375000                  0   \n",
      "2                  77.419355                  59.375000                  0   \n",
      "3                  60.655738                  61.194030                  1   \n",
      "4                  67.741935                  58.064516                  1   \n",
      "\n",
      "   toss_decision_bat  match_id  \n",
      "0                  0    656399  \n",
      "1                  0    656401  \n",
      "2                  0    656403  \n",
      "3                  1    656405  \n",
      "4                  0    656407  \n",
      "(1118, 14)\n",
      "Index(['winner_binary', 'season', 'team1', 'team2', 'runs_difference',\n",
      "       'wickets_difference', 'boundary_difference', 'team1_wickets',\n",
      "       'team2_wickets', 'team1_dot_ball_percentage',\n",
      "       'team2_dot_ball_percentage', 'toss_won_by_team1', 'toss_decision_bat',\n",
      "       'match_id'],\n",
      "      dtype='object')\n",
      "winner_binary                  int64\n",
      "season                        object\n",
      "team1                         object\n",
      "team2                         object\n",
      "runs_difference                int64\n",
      "wickets_difference             int64\n",
      "boundary_difference            int64\n",
      "team1_wickets                  int64\n",
      "team2_wickets                  int64\n",
      "team1_dot_ball_percentage    float64\n",
      "team2_dot_ball_percentage    float64\n",
      "toss_won_by_team1              int64\n",
      "toss_decision_bat              int64\n",
      "match_id                       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Suppose your DataFrame is called 'data'\n",
    "print(modeling_data.head())            # Show first 5 rows\n",
    "print(modeling_data.shape)             # Show number of rows and columns\n",
    "print(modeling_data.columns)           # List all column names\n",
    "print(modeling_data.dtypes)            # Show each column’s data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb40cd93",
   "metadata": {},
   "source": [
    "## Saving our Dataframe to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4bbee0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data['season'] = modeling_data['season'].astype(str)\n",
    "modeling_data['team1'] = modeling_data['team1'].astype(str)\n",
    "modeling_data['team2'] = modeling_data['team2'].astype(str)\n",
    "modeling_data.to_csv(\"cricket_model_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee159d36",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd4f5485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6042553191489362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       120\n",
      "           1       0.59      0.60      0.60       115\n",
      "\n",
      "    accuracy                           0.60       235\n",
      "   macro avg       0.60      0.60      0.60       235\n",
      "weighted avg       0.60      0.60      0.60       235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Aggregate to match level (simplified)\n",
    "match_df = data.groupby(\"match_id\").agg({\n",
    "    \"runs_off_bat\": \"sum\",\n",
    "    \"extras\": \"sum\",\n",
    "    \"batting_team\": \"first\",\n",
    "    \"bowling_team\": \"first\",\n",
    "    \"venue\": \"first\",\n",
    "    \"toss_winner\": \"first\",\n",
    "    \"toss_decision\": \"first\",\n",
    "    \"winner\": \"first\"\n",
    "}).reset_index()\n",
    "\n",
    "# Binary target: did team1 win?\n",
    "match_df[\"team1_win\"] = (match_df[\"winner\"] == match_df[\"batting_team\"]).astype(int)\n",
    "\n",
    "# Encode categorical features\n",
    "X = pd.get_dummies(match_df.drop(columns=[\"winner\", \"team1_win\", \"match_id\"]))\n",
    "y = match_df[\"team1_win\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1c22be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load your cricket ball-by-ball data as 'data' DataFrame\n",
      "\n",
      "Then run:\n",
      "  predictor = CricketMatchPredictor(data)\n",
      "  results = predictor.run_full_pipeline(quick_tune=True)\n",
      "\n",
      "Quick tune=True for faster testing, False for thorough optimization\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class CricketMatchPredictor:\n",
    "    \"\"\"\n",
    "    Comprehensive cricket match prediction system with feature engineering,\n",
    "    hyperparameter tuning, and proper evaluation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initialize predictor with ball-by-ball data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pd.DataFrame\n",
    "            Ball-by-ball cricket match data\n",
    "        \"\"\"\n",
    "        self.data = data.copy()\n",
    "        self.label_encoders = {}\n",
    "        self.model = None\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def clean_data(self):\n",
    "        \"\"\"Step 1: Data cleaning and preprocessing\"\"\"\n",
    "        print(\"=\" * 70)\n",
    "        print(\"STEP 1: DATA CLEANING\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Convert date to datetime\n",
    "        self.data['start_date'] = pd.to_datetime(self.data['start_date'])\n",
    "        \n",
    "        # Handle missing values\n",
    "        print(f\"\\nMissing values before cleaning:\")\n",
    "        print(self.data.isnull().sum()[self.data.isnull().sum() > 0])\n",
    "        \n",
    "        # Fill missing categorical values\n",
    "        cat_cols = ['wicket_type', 'player_dismissed', 'other_wicket_type', \n",
    "                    'other_player_dismissed', 'bowling_style', 'batting_style']\n",
    "        for col in cat_cols:\n",
    "            if col in self.data.columns:\n",
    "                self.data[col] = self.data[col].fillna('None')\n",
    "        \n",
    "        # Fill missing numerical values with 0\n",
    "        num_cols = ['wides', 'noballs', 'byes', 'legbyes', 'penalty']\n",
    "        for col in num_cols:\n",
    "            if col in self.data.columns:\n",
    "                self.data[col] = self.data[col].fillna(0)\n",
    "        \n",
    "        # Remove matches with no winner (tie/no result)\n",
    "        initial_matches = self.data['match_id'].nunique()\n",
    "        self.data = self.data[self.data['winner'].notna()]\n",
    "        final_matches = self.data['match_id'].nunique()\n",
    "        print(f\"\\nMatches: {initial_matches} -> {final_matches} (removed {initial_matches - final_matches} ties/no results)\")\n",
    "        \n",
    "        print(\"\\n✓ Data cleaning completed\")\n",
    "        \n",
    "    def create_match_level_features(self):\n",
    "        \"\"\"Step 2: Aggregate ball-by-ball to match-level with engineered features\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 2: FEATURE ENGINEERING\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        match_features = []\n",
    "        \n",
    "        for match_id in self.data['match_id'].unique():\n",
    "            match_data = self.data[self.data['match_id'] == match_id]\n",
    "            \n",
    "            # Basic match info\n",
    "            feature_dict = {\n",
    "                'match_id': match_id,\n",
    "                'season': match_data['season'].iloc[0],\n",
    "                'start_date': match_data['start_date'].iloc[0],\n",
    "                'venue': match_data['venue'].iloc[0],\n",
    "                'winner': match_data['winner'].iloc[0],\n",
    "                'toss_winner': match_data['toss_winner'].iloc[0],\n",
    "                'toss_decision': match_data['toss_decision'].iloc[0],\n",
    "                'team1': match_data['team1'].iloc[0],\n",
    "                'team2': match_data['team2'].iloc[0]\n",
    "            }\n",
    "            \n",
    "            # Calculate match statistics for each team\n",
    "            for team in [feature_dict['team1'], feature_dict['team2']]:\n",
    "                team_batting = match_data[match_data['batting_team'] == team]\n",
    "                team_bowling = match_data[match_data['bowling_team'] == team]\n",
    "                \n",
    "                prefix = 'team1' if team == feature_dict['team1'] else 'team2'\n",
    "                \n",
    "                # Batting stats\n",
    "                feature_dict[f'{prefix}_total_runs'] = (\n",
    "                    team_batting['runs_off_bat'].sum() + team_batting['extras'].sum()\n",
    "                )\n",
    "                feature_dict[f'{prefix}_boundaries'] = len(team_batting[team_batting['runs_off_bat'].isin([4, 6])])\n",
    "                feature_dict[f'{prefix}_sixes'] = len(team_batting[team_batting['runs_off_bat'] == 6])\n",
    "                feature_dict[f'{prefix}_dots'] = len(team_batting[team_batting['runs_off_bat'] == 0])\n",
    "                \n",
    "                # Bowling stats (wickets taken by opposition)\n",
    "                feature_dict[f'{prefix}_wickets_lost'] = team_batting['wicket_type'].notna().sum()\n",
    "                feature_dict[f'{prefix}_extras_given'] = team_bowling['extras'].sum()\n",
    "                feature_dict[f'{prefix}_wides'] = team_bowling['wides'].sum()\n",
    "                \n",
    "                # Calculate run rate (runs per over)\n",
    "                balls_faced = len(team_batting)\n",
    "                if balls_faced > 0:\n",
    "                    overs = balls_faced / 6\n",
    "                    feature_dict[f'{prefix}_run_rate'] = feature_dict[f'{prefix}_total_runs'] / overs if overs > 0 else 0\n",
    "                else:\n",
    "                    feature_dict[f'{prefix}_run_rate'] = 0\n",
    "                \n",
    "                # Strike rate indicators\n",
    "                if balls_faced > 0:\n",
    "                    feature_dict[f'{prefix}_boundary_pct'] = feature_dict[f'{prefix}_boundaries'] / balls_faced * 100\n",
    "                    feature_dict[f'{prefix}_dot_pct'] = feature_dict[f'{prefix}_dots'] / balls_faced * 100\n",
    "                else:\n",
    "                    feature_dict[f'{prefix}_boundary_pct'] = 0\n",
    "                    feature_dict[f'{prefix}_dot_pct'] = 0\n",
    "            \n",
    "            # Toss advantage\n",
    "            feature_dict['toss_winner_is_team1'] = 1 if feature_dict['toss_winner'] == feature_dict['team1'] else 0\n",
    "            feature_dict['toss_and_bat'] = 1 if feature_dict['toss_decision'] == 'bat' else 0\n",
    "            \n",
    "            # Winner encoding\n",
    "            feature_dict['team1_won'] = 1 if feature_dict['winner'] == feature_dict['team1'] else 0\n",
    "            \n",
    "            match_features.append(feature_dict)\n",
    "        \n",
    "        self.match_df = pd.DataFrame(match_features)\n",
    "        \n",
    "        # Sort by date for time-series features\n",
    "        self.match_df = self.match_df.sort_values('start_date').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\n✓ Created {len(self.match_df)} match-level records\")\n",
    "        print(f\"✓ Generated {len(self.match_df.columns)} initial features\")\n",
    "        \n",
    "    def create_historical_features(self, lookback=5):\n",
    "        \"\"\"Create rolling statistics for team performance\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"STEP 3: HISTORICAL FEATURES (Last {lookback} matches)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        teams = pd.concat([self.match_df['team1'], self.match_df['team2']]).unique()\n",
    "        \n",
    "        # Initialize historical feature columns\n",
    "        hist_features = ['wins', 'matches', 'avg_runs', 'avg_wickets', 'avg_run_rate']\n",
    "        for prefix in ['team1', 'team2']:\n",
    "            for feat in hist_features:\n",
    "                self.match_df[f'{prefix}_last{lookback}_{feat}'] = 0.0\n",
    "        \n",
    "        # Calculate rolling statistics\n",
    "        for team in teams:\n",
    "            # Get all matches for this team\n",
    "            team_matches = self.match_df[\n",
    "                (self.match_df['team1'] == team) | (self.match_df['team2'] == team)\n",
    "            ].copy()\n",
    "            \n",
    "            for idx in team_matches.index:\n",
    "                # Get previous matches (before current match)\n",
    "                prev_matches = team_matches[team_matches.index < idx].tail(lookback)\n",
    "                \n",
    "                if len(prev_matches) > 0:\n",
    "                    # Calculate statistics\n",
    "                    wins = 0\n",
    "                    total_runs = 0\n",
    "                    total_wickets = 0\n",
    "                    total_run_rate = 0\n",
    "                    \n",
    "                    for _, match in prev_matches.iterrows():\n",
    "                        if match['team1'] == team:\n",
    "                            wins += match['team1_won']\n",
    "                            total_runs += match['team1_total_runs']\n",
    "                            total_wickets += match['team1_wickets_lost']\n",
    "                            total_run_rate += match['team1_run_rate']\n",
    "                        else:\n",
    "                            wins += (1 - match['team1_won'])\n",
    "                            total_runs += match['team2_total_runs']\n",
    "                            total_wickets += match['team2_wickets_lost']\n",
    "                            total_run_rate += match['team2_run_rate']\n",
    "                    \n",
    "                    n = len(prev_matches)\n",
    "                    win_rate = wins / n\n",
    "                    avg_runs = total_runs / n\n",
    "                    avg_wickets = total_wickets / n\n",
    "                    avg_run_rate = total_run_rate / n\n",
    "                    \n",
    "                    # Assign to correct team column\n",
    "                    if self.match_df.loc[idx, 'team1'] == team:\n",
    "                        prefix = 'team1'\n",
    "                    else:\n",
    "                        prefix = 'team2'\n",
    "                    \n",
    "                    self.match_df.loc[idx, f'{prefix}_last{lookback}_wins'] = wins\n",
    "                    self.match_df.loc[idx, f'{prefix}_last{lookback}_matches'] = n\n",
    "                    self.match_df.loc[idx, f'{prefix}_last{lookback}_avg_runs'] = avg_runs\n",
    "                    self.match_df.loc[idx, f'{prefix}_last{lookback}_avg_wickets'] = avg_wickets\n",
    "                    self.match_df.loc[idx, f'{prefix}_last{lookback}_avg_run_rate'] = avg_run_rate\n",
    "        \n",
    "        # Calculate win rate\n",
    "        for prefix in ['team1', 'team2']:\n",
    "            self.match_df[f'{prefix}_last{lookback}_win_rate'] = (\n",
    "                self.match_df[f'{prefix}_last{lookback}_wins'] / \n",
    "                self.match_df[f'{prefix}_last{lookback}_matches'].replace(0, 1)\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n✓ Added historical performance features\")\n",
    "        \n",
    "    def create_head_to_head_features(self):\n",
    "        \"\"\"Create head-to-head statistics between teams\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 4: HEAD-TO-HEAD FEATURES\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        self.match_df['h2h_team1_wins'] = 0\n",
    "        self.match_df['h2h_team2_wins'] = 0\n",
    "        self.match_df['h2h_matches'] = 0\n",
    "        \n",
    "        for idx in self.match_df.index:\n",
    "            team1 = self.match_df.loc[idx, 'team1']\n",
    "            team2 = self.match_df.loc[idx, 'team2']\n",
    "            \n",
    "            # Get previous h2h matches\n",
    "            prev_h2h = self.match_df[\n",
    "                (self.match_df.index < idx) &\n",
    "                (\n",
    "                    ((self.match_df['team1'] == team1) & (self.match_df['team2'] == team2)) |\n",
    "                    ((self.match_df['team1'] == team2) & (self.match_df['team2'] == team1))\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            if len(prev_h2h) > 0:\n",
    "                team1_wins = 0\n",
    "                for _, match in prev_h2h.iterrows():\n",
    "                    if match['winner'] == team1:\n",
    "                        team1_wins += 1\n",
    "                \n",
    "                self.match_df.loc[idx, 'h2h_team1_wins'] = team1_wins\n",
    "                self.match_df.loc[idx, 'h2h_team2_wins'] = len(prev_h2h) - team1_wins\n",
    "                self.match_df.loc[idx, 'h2h_matches'] = len(prev_h2h)\n",
    "        \n",
    "        # H2H win rate\n",
    "        self.match_df['h2h_team1_win_rate'] = (\n",
    "            self.match_df['h2h_team1_wins'] / \n",
    "            self.match_df['h2h_matches'].replace(0, 1)\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n✓ Added head-to-head features\")\n",
    "        \n",
    "    def prepare_features(self):\n",
    "        \"\"\"Prepare final feature set for modeling\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 5: FEATURE PREPARATION\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        categorical_cols = ['venue', 'toss_decision']\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            self.match_df[f'{col}_encoded'] = le.fit_transform(self.match_df[col])\n",
    "            self.label_encoders[col] = le\n",
    "        \n",
    "        # Select features for modeling\n",
    "        feature_cols = [\n",
    "            # Toss features\n",
    "            'toss_winner_is_team1', 'toss_and_bat',\n",
    "            'venue_encoded', 'toss_decision_encoded',\n",
    "            \n",
    "            # Match statistics\n",
    "            'team1_total_runs', 'team1_wickets_lost', 'team1_run_rate',\n",
    "            'team1_boundaries', 'team1_sixes', 'team1_boundary_pct', 'team1_dot_pct',\n",
    "            'team2_total_runs', 'team2_wickets_lost', 'team2_run_rate',\n",
    "            'team2_boundaries', 'team2_sixes', 'team2_boundary_pct', 'team2_dot_pct',\n",
    "            \n",
    "            # Historical features (last 5 matches)\n",
    "            'team1_last5_win_rate', 'team1_last5_avg_runs', 'team1_last5_avg_wickets', 'team1_last5_avg_run_rate',\n",
    "            'team2_last5_win_rate', 'team2_last5_avg_runs', 'team2_last5_avg_wickets', 'team2_last5_avg_run_rate',\n",
    "            \n",
    "            # Head-to-head\n",
    "            'h2h_team1_win_rate', 'h2h_matches'\n",
    "        ]\n",
    "        \n",
    "        # Remove rows with insufficient historical data\n",
    "        initial_rows = len(self.match_df)\n",
    "        self.match_df = self.match_df[self.match_df['h2h_matches'] > 0]\n",
    "        print(f\"\\n✓ Removed {initial_rows - len(self.match_df)} matches with no historical data\")\n",
    "        \n",
    "        self.X = self.match_df[feature_cols].fillna(0)\n",
    "        self.y = self.match_df['team1_won']\n",
    "        self.feature_names = feature_cols\n",
    "        \n",
    "        print(f\"✓ Final feature set: {len(feature_cols)} features\")\n",
    "        print(f\"✓ Training samples: {len(self.X)}\")\n",
    "        print(f\"✓ Class distribution: {self.y.value_counts().to_dict()}\")\n",
    "        \n",
    "        return self.X, self.y\n",
    "    \n",
    "    def split_data(self, test_size=0.2, time_series_split=True):\n",
    "        \"\"\"Split data with proper time-series consideration\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 6: TRAIN-TEST SPLIT\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if time_series_split:\n",
    "            # Split by time to avoid data leakage\n",
    "            split_idx = int(len(self.X) * (1 - test_size))\n",
    "            self.X_train = self.X.iloc[:split_idx]\n",
    "            self.X_test = self.X.iloc[split_idx:]\n",
    "            self.y_train = self.y.iloc[:split_idx]\n",
    "            self.y_test = self.y.iloc[split_idx:]\n",
    "            print(f\"\\n✓ Time-series split (train on past, test on recent matches)\")\n",
    "        else:\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "                self.X, self.y, test_size=test_size, random_state=42, stratify=self.y\n",
    "            )\n",
    "            print(f\"\\n✓ Random stratified split\")\n",
    "        \n",
    "        print(f\"✓ Train set: {len(self.X_train)} samples\")\n",
    "        print(f\"✓ Test set: {len(self.X_test)} samples\")\n",
    "        \n",
    "    def tune_hyperparameters(self, quick_mode=False):\n",
    "        \"\"\"Hyperparameter tuning with GridSearchCV\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 7: HYPERPARAMETER TUNING\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if quick_mode:\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [10, 20],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'max_features': ['sqrt']\n",
    "            }\n",
    "            print(\"\\n⚡ Quick mode enabled (reduced parameter space)\")\n",
    "        else:\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200, 300, 500],\n",
    "                'max_depth': [5, 10, 20, None],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'max_features': ['sqrt', 'log2', None]\n",
    "            }\n",
    "        \n",
    "        rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        print(f\"\\nSearching {np.prod([len(v) for v in param_grid.values()])} combinations...\")\n",
    "        \n",
    "        grid = GridSearchCV(\n",
    "            rf, param_grid, cv=cv, scoring='accuracy', \n",
    "            n_jobs=-1, verbose=1\n",
    "        )\n",
    "        \n",
    "        grid.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        print(f\"\\n✓ Best parameters found:\")\n",
    "        for param, value in grid.best_params_.items():\n",
    "            print(f\"  • {param}: {value}\")\n",
    "        \n",
    "        print(f\"\\n✓ Best CV accuracy: {grid.best_score_:.4f}\")\n",
    "        \n",
    "        self.model = grid.best_estimator_\n",
    "        return grid.best_params_\n",
    "    \n",
    "    def train_model(self, use_tuned=True, **kwargs):\n",
    "        \"\"\"Train the Random Forest model\"\"\"\n",
    "        if not use_tuned or self.model is None:\n",
    "            print(\"\\n\" + \"=\" * 70)\n",
    "            print(\"STEP 7: TRAINING MODEL (Default Parameters)\")\n",
    "            print(\"=\" * 70)\n",
    "            self.model = RandomForestClassifier(\n",
    "                n_estimators=kwargs.get('n_estimators', 200),\n",
    "                max_depth=kwargs.get('max_depth', 20),\n",
    "                min_samples_split=kwargs.get('min_samples_split', 5),\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "            print(\"\\n✓ Model trained successfully\")\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 8: MODEL EVALUATION\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Predictions\n",
    "        y_train_pred = self.model.predict(self.X_train)\n",
    "        y_test_pred = self.model.predict(self.X_test)\n",
    "        \n",
    "        y_test_proba = self.model.predict_proba(self.X_test)[:, 1]\n",
    "        \n",
    "        # Accuracy\n",
    "        train_acc = accuracy_score(self.y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(self.y_test, y_test_pred)\n",
    "        \n",
    "        print(f\"\\n📊 ACCURACY\")\n",
    "        print(f\"  • Training Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "        print(f\"  • Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "        print(f\"  • Overfit Margin: {(train_acc - test_acc)*100:.2f}%\")\n",
    "        \n",
    "        # Classification Report\n",
    "        print(f\"\\n📋 CLASSIFICATION REPORT (Test Set)\")\n",
    "        print(classification_report(self.y_test, y_test_pred, \n",
    "                                     target_names=['Team 2 Wins', 'Team 1 Wins']))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(self.y_test, y_test_pred)\n",
    "        print(f\"\\n📉 CONFUSION MATRIX\")\n",
    "        print(f\"                Predicted\")\n",
    "        print(f\"                0      1\")\n",
    "        print(f\"Actual   0   {cm[0,0]:4d}  {cm[0,1]:4d}\")\n",
    "        print(f\"         1   {cm[1,0]:4d}  {cm[1,1]:4d}\")\n",
    "        \n",
    "        # ROC-AUC\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(self.y_test, y_test_proba)\n",
    "            print(f\"\\n🎯 ROC-AUC Score: {roc_auc:.4f}\")\n",
    "        except:\n",
    "            print(f\"\\n⚠ ROC-AUC not available\")\n",
    "        \n",
    "        # Cross-validation score\n",
    "        cv_scores = cross_val_score(self.model, self.X_train, self.y_train, \n",
    "                                     cv=5, scoring='accuracy')\n",
    "        print(f\"\\n✅ Cross-Validation Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "        \n",
    "        return {\n",
    "            'train_accuracy': train_acc,\n",
    "            'test_accuracy': test_acc,\n",
    "            'cv_scores': cv_scores,\n",
    "            'confusion_matrix': cm\n",
    "        }\n",
    "    \n",
    "    def plot_feature_importance(self, top_n=15):\n",
    "        \"\"\"Visualize feature importance\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 9: FEATURE IMPORTANCE ANALYSIS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        importances = self.model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        print(f\"\\n🔝 Top {top_n} Most Important Features:\")\n",
    "        for i in range(min(top_n, len(self.feature_names))):\n",
    "            idx = indices[i]\n",
    "            print(f\"  {i+1:2d}. {self.feature_names[idx]:40s} {importances[idx]:.4f}\")\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        top_indices = indices[:top_n]\n",
    "        plt.barh(range(top_n), importances[top_indices])\n",
    "        plt.yticks(range(top_n), [self.feature_names[i] for i in top_indices])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title(f'Top {top_n} Feature Importances')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"\\n✓ Feature importance plot saved as 'feature_importance.png'\")\n",
    "        plt.close()\n",
    "        \n",
    "    def predict_match(self, team1_name, team2_name, venue_name, toss_winner_name, toss_decision):\n",
    "        \"\"\"Predict outcome of a new match\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"MATCH PREDICTION\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"\\nTeam 1: {team1_name}\")\n",
    "        print(f\"Team 2: {team2_name}\")\n",
    "        print(f\"Venue: {venue_name}\")\n",
    "        print(f\"Toss Winner: {toss_winner_name}\")\n",
    "        print(f\"Toss Decision: {toss_decision}\")\n",
    "        \n",
    "        # This would require looking up recent stats for these teams\n",
    "        # For demonstration, returning prediction format\n",
    "        print(\"\\n⚠ Note: Real-time prediction requires current team statistics\")\n",
    "        print(\"Use the trained model with actual feature values for predictions\")\n",
    "    \n",
    "    def run_full_pipeline(self, quick_tune=False, time_series_split=True):\n",
    "        \"\"\"Execute complete pipeline\"\"\"\n",
    "        print(\"\\n\" + \"🏏\" * 35)\n",
    "        print(\" \" * 20 + \"CRICKET MATCH PREDICTION SYSTEM\")\n",
    "        print(\" \" * 20 + \"Random Forest with Feature Engineering\")\n",
    "        print(\"🏏\" * 35 + \"\\n\")\n",
    "        \n",
    "        # Execute all steps\n",
    "        self.clean_data()\n",
    "        self.create_match_level_features()\n",
    "        self.create_historical_features(lookback=5)\n",
    "        self.create_head_to_head_features()\n",
    "        self.prepare_features()\n",
    "        self.split_data(test_size=0.2, time_series_split=time_series_split)\n",
    "        self.tune_hyperparameters(quick_mode=quick_tune)\n",
    "        results = self.evaluate_model()\n",
    "        self.plot_feature_importance(top_n=15)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"🎉 PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"\\n📈 Final Test Accuracy: {results['test_accuracy']*100:.2f}%\")\n",
    "        print(f\"✨ Model ready for predictions!\\n\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# USAGE EXAMPLE\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your data\n",
    "    # data = pd.read_csv('your_cricket_data.csv')\n",
    "    \n",
    "    # Example with placeholder:\n",
    "    print(\"Load your cricket ball-by-ball data as 'data' DataFrame\")\n",
    "    print(\"\\nThen run:\")\n",
    "    print(\"  predictor = CricketMatchPredictor(data)\")\n",
    "    print(\"  results = predictor.run_full_pipeline(quick_tune=True)\")\n",
    "    print(\"\\nQuick tune=True for faster testing, False for thorough optimization\")\n",
    "    \n",
    "    # Uncomment below when you have data loaded:\n",
    "    \"\"\"\n",
    "    predictor = CricketMatchPredictor(data)\n",
    "    results = predictor.run_full_pipeline(\n",
    "        quick_tune=False,  # Set True for quick testing\n",
    "        time_series_split=True  # Recommended for cricket predictions\n",
    "    )\n",
    "    \n",
    "    # Access the trained model\n",
    "    model = predictor.model\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': predictor.feature_names,\n",
    "        'importance': predictor.model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45f1e1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTo use this predictor with your cricket data:\\n\\n1. Load your data (assuming it's in a DataFrame called 'data'):\\n\\n   predictor = CricketMatchPredictor(data)\\n\\n2. Run the full pipeline:\\n\\n   results = predictor.run_full_pipeline(\\n       quick_tune=True,  # Set False for thorough hyperparameter tuning\\n       time_series_split=True  # Train on past matches, test on recent ones\\n   )\\n\\n3. Access the trained model and results:\\n\\n   model = predictor.model\\n   X_test = predictor.X_test\\n   y_test = predictor.y_test\\n   predictions = model.predict(X_test)\\n\\n4. View feature importance:\\n\\n   feature_importance = pd.DataFrame({\\n       'feature': predictor.feature_names,\\n       'importance': predictor.model.feature_importances_\\n   }).sort_values('importance', ascending=False)\\n\\n   print(feature_importance.head(10))\\n\\nExample complete workflow:\\n\\n   # Assuming 'data' is your DataFrame with ball-by-ball cricket data\\n   predictor = CricketMatchPredictor(data)\\n   results = predictor.run_full_pipeline(quick_tune=True)\\n\\n   # Now you can use predictor.model for predictions\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class CricketMatchPredictor:\n",
    "    \"\"\"\n",
    "    Comprehensive cricket match prediction system with feature engineering,\n",
    "    hyperparameter tuning, and proper evaluation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initialize predictor with ball-by-ball data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pd.DataFrame\n",
    "            Ball-by-ball cricket match data\n",
    "        \"\"\"\n",
    "        self.data = data.copy()\n",
    "        self.label_encoders = {}\n",
    "        self.model = None\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def clean_data(self):\n",
    "        \"\"\"Step 1: Data cleaning and preprocessing\"\"\"\n",
    "        print(\"=\" * 70)\n",
    "        print(\"STEP 1: DATA CLEANING\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Convert date to datetime\n",
    "        self.data['start_date'] = pd.to_datetime(self.data['start_date'])\n",
    "        \n",
    "        # Handle missing values\n",
    "        print(f\"\\nMissing values before cleaning:\")\n",
    "        print(self.data.isnull().sum()[self.data.isnull().sum() > 0])\n",
    "        \n",
    "        # Fill missing categorical values\n",
    "        cat_cols = ['wicket_type', 'player_dismissed', 'other_wicket_type', \n",
    "                    'other_player_dismissed', 'bowling_style', 'batting_style']\n",
    "        for col in cat_cols:\n",
    "            if col in self.data.columns:\n",
    "                self.data[col] = self.data[col].fillna('None')\n",
    "        \n",
    "        # Fill missing numerical values with 0\n",
    "        num_cols = ['wides', 'noballs', 'byes', 'legbyes', 'penalty']\n",
    "        for col in num_cols:\n",
    "            if col in self.data.columns:\n",
    "                self.data[col] = self.data[col].fillna(0)\n",
    "        \n",
    "        # Remove matches with no winner (tie/no result)\n",
    "        initial_matches = self.data['match_id'].nunique()\n",
    "        self.data = self.data[self.data['winner'].notna()]\n",
    "        final_matches = self.data['match_id'].nunique()\n",
    "        print(f\"\\nMatches: {initial_matches} -> {final_matches} (removed {initial_matches - final_matches} ties/no results)\")\n",
    "        \n",
    "        print(\"\\n✓ Data cleaning completed\")\n",
    "        \n",
    "    def create_match_level_features(self):\n",
    "        \"\"\"Step 2: Aggregate ball-by-ball to match-level with engineered features\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 2: FEATURE ENGINEERING\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        match_features = []\n",
    "        \n",
    "        for match_id in self.data['match_id'].unique():\n",
    "            match_data = self.data[self.data['match_id'] == match_id]\n",
    "            \n",
    "            # Basic match info\n",
    "            feature_dict = {\n",
    "                'match_id': match_id,\n",
    "                'season': match_data['season'].iloc[0],\n",
    "                'start_date': match_data['start_date'].iloc[0],\n",
    "                'venue': match_data['venue'].iloc[0],\n",
    "                'winner': match_data['winner'].iloc[0],\n",
    "                'toss_winner': match_data['toss_winner'].iloc[0],\n",
    "                'toss_decision': match_data['toss_decision'].iloc[0],\n",
    "                'team1': match_data['team1'].iloc[0],\n",
    "                'team2': match_data['team2'].iloc[0]\n",
    "            }\n",
    "            \n",
    "            # Calculate match statistics for each team\n",
    "            for team in [feature_dict['team1'], feature_dict['team2']]:\n",
    "                team_batting = match_data[match_data['batting_team'] == team]\n",
    "                team_bowling = match_data[match_data['bowling_team'] == team]\n",
    "                \n",
    "                prefix = 'team1' if team == feature_dict['team1'] else 'team2'\n",
    "                \n",
    "                # Batting stats\n",
    "                feature_dict[f'{prefix}_total_runs'] = (\n",
    "                    team_batting['runs_off_bat'].sum() + team_batting['extras'].sum()\n",
    "                )\n",
    "                feature_dict[f'{prefix}_boundaries'] = len(team_batting[team_batting['runs_off_bat'].isin([4, 6])])\n",
    "                feature_dict[f'{prefix}_sixes'] = len(team_batting[team_batting['runs_off_bat'] == 6])\n",
    "                feature_dict[f'{prefix}_dots'] = len(team_batting[team_batting['runs_off_bat'] == 0])\n",
    "                \n",
    "                # Bowling stats (wickets taken by opposition)\n",
    "                feature_dict[f'{prefix}_wickets_lost'] = team_batting['wicket_type'].notna().sum()\n",
    "                feature_dict[f'{prefix}_extras_given'] = team_bowling['extras'].sum()\n",
    "                feature_dict[f'{prefix}_wides'] = team_bowling['wides'].sum()\n",
    "                \n",
    "                # Calculate run rate (runs per over)\n",
    "                balls_faced = len(team_batting)\n",
    "                if balls_faced > 0:\n",
    "                    overs = balls_faced / 6\n",
    "                    feature_dict[f'{prefix}_run_rate'] = feature_dict[f'{prefix}_total_runs'] / overs if overs > 0 else 0\n",
    "                else:\n",
    "                    feature_dict[f'{prefix}_run_rate'] = 0\n",
    "                \n",
    "                # Strike rate indicators\n",
    "                if balls_faced > 0:\n",
    "                    feature_dict[f'{prefix}_boundary_pct'] = feature_dict[f'{prefix}_boundaries'] / balls_faced * 100\n",
    "                    feature_dict[f'{prefix}_dot_pct'] = feature_dict[f'{prefix}_dots'] / balls_faced * 100\n",
    "                else:\n",
    "                    feature_dict[f'{prefix}_boundary_pct'] = 0\n",
    "                    feature_dict[f'{prefix}_dot_pct'] = 0\n",
    "            \n",
    "            # Toss advantage\n",
    "            feature_dict['toss_winner_is_team1'] = 1 if feature_dict['toss_winner'] == feature_dict['team1'] else 0\n",
    "            feature_dict['toss_and_bat'] = 1 if feature_dict['toss_decision'] == 'bat' else 0\n",
    "            \n",
    "            # Winner encoding\n",
    "            feature_dict['team1_won'] = 1 if feature_dict['winner'] == feature_dict['team1'] else 0\n",
    "            \n",
    "            match_features.append(feature_dict)\n",
    "        \n",
    "        self.match_df = pd.DataFrame(match_features)\n",
    "        \n",
    "        # Sort by date for time-series features\n",
    "        self.match_df = self.match_df.sort_values('start_date').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\n✓ Created {len(self.match_df)} match-level records\")\n",
    "        print(f\"✓ Generated {len(self.match_df.columns)} initial features\")\n",
    "        \n",
    "    def create_historical_features(self, lookback=5):\n",
    "        \"\"\"Create rolling statistics for team performance\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"STEP 3: HISTORICAL FEATURES (Last {lookback} matches)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        teams = pd.concat([self.match_df['team1'], self.match_df['team2']]).unique()\n",
    "        \n",
    "        # Initialize historical feature columns\n",
    "        hist_features = ['wins', 'matches', 'avg_runs', 'avg_wickets', 'avg_run_rate']\n",
    "        for prefix in ['team1', 'team2']:\n",
    "            for feat in hist_features:\n",
    "                self.match_df[f'{prefix}_last{lookback}_{feat}'] = 0.0\n",
    "        \n",
    "        # Calculate rolling statistics\n",
    "        for team in teams:\n",
    "            # Get all matches for this team\n",
    "            team_matches = self.match_df[\n",
    "                (self.match_df['team1'] == team) | (self.match_df['team2'] == team)\n",
    "            ].copy()\n",
    "            \n",
    "            for idx in team_matches.index:\n",
    "                # Get previous matches (before current match)\n",
    "                prev_matches = team_matches[team_matches.index < idx].tail(lookback)\n",
    "                \n",
    "                if len(prev_matches) > 0:\n",
    "                    # Calculate statistics\n",
    "                    wins = 0\n",
    "                    total_runs = 0\n",
    "                    total_wickets = 0\n",
    "                    total_run_rate = 0\n",
    "                    \n",
    "                    for _, match in prev_matches.iterrows():\n",
    "                        if match['team1'] == team:\n",
    "                            wins += match['team1_won']\n",
    "                            total_runs += match['team1_total_runs']\n",
    "                            total_wickets += match['team1_wickets_lost']\n",
    "                            total_run_rate += match['team1_run_rate']\n",
    "                        else:\n",
    "                            wins += (1 - match['team1_won'])\n",
    "                            total_runs += match['team2_total_runs']\n",
    "                            total_wickets += match['team2_wickets_lost']\n",
    "                            total_run_rate += match['team2_run_rate']\n",
    "                    \n",
    "                    n = len(prev_matches)\n",
    "                    win_rate = wins / n\n",
    "                    avg_runs = total_runs / n\n",
    "                    avg_wickets = total_wickets / n\n",
    "                    avg_run_rate = total_run_rate / n\n",
    "                    \n",
    "                    # Assign to correct team column\n",
    "                    if self.match_df.loc[idx, 'team1'] == team:\n",
    "                        prefix = 'team1'\n",
    "                    else:\n",
    "                        prefix = 'team2'\n",
    "                    \n",
    "                    self.match_df.loc[idx, f'{prefix}_last{lookback}_wins'] = wins\n",
    "                    self.match_df.loc[idx, f'{prefix}_last{lookback}_matches'] = n\n",
    "                    self.match_df.loc[idx, f'{prefix}_last{lookback}_avg_runs'] = avg_runs\n",
    "                    self.match_df.loc[idx, f'{prefix}_last{lookback}_avg_wickets'] = avg_wickets\n",
    "                    self.match_df.loc[idx, f'{prefix}_last{lookback}_avg_run_rate'] = avg_run_rate\n",
    "        \n",
    "        # Calculate win rate\n",
    "        for prefix in ['team1', 'team2']:\n",
    "            self.match_df[f'{prefix}_last{lookback}_win_rate'] = (\n",
    "                self.match_df[f'{prefix}_last{lookback}_wins'] / \n",
    "                self.match_df[f'{prefix}_last{lookback}_matches'].replace(0, 1)\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n✓ Added historical performance features\")\n",
    "        \n",
    "    def create_head_to_head_features(self):\n",
    "        \"\"\"Create head-to-head statistics between teams\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 4: HEAD-TO-HEAD FEATURES\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        self.match_df['h2h_team1_wins'] = 0\n",
    "        self.match_df['h2h_team2_wins'] = 0\n",
    "        self.match_df['h2h_matches'] = 0\n",
    "        \n",
    "        for idx in self.match_df.index:\n",
    "            team1 = self.match_df.loc[idx, 'team1']\n",
    "            team2 = self.match_df.loc[idx, 'team2']\n",
    "            \n",
    "            # Get previous h2h matches\n",
    "            prev_h2h = self.match_df[\n",
    "                (self.match_df.index < idx) &\n",
    "                (\n",
    "                    ((self.match_df['team1'] == team1) & (self.match_df['team2'] == team2)) |\n",
    "                    ((self.match_df['team1'] == team2) & (self.match_df['team2'] == team1))\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            if len(prev_h2h) > 0:\n",
    "                team1_wins = 0\n",
    "                for _, match in prev_h2h.iterrows():\n",
    "                    if match['winner'] == team1:\n",
    "                        team1_wins += 1\n",
    "                \n",
    "                self.match_df.loc[idx, 'h2h_team1_wins'] = team1_wins\n",
    "                self.match_df.loc[idx, 'h2h_team2_wins'] = len(prev_h2h) - team1_wins\n",
    "                self.match_df.loc[idx, 'h2h_matches'] = len(prev_h2h)\n",
    "        \n",
    "        # H2H win rate\n",
    "        self.match_df['h2h_team1_win_rate'] = (\n",
    "            self.match_df['h2h_team1_wins'] / \n",
    "            self.match_df['h2h_matches'].replace(0, 1)\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n✓ Added head-to-head features\")\n",
    "        \n",
    "    def prepare_features(self):\n",
    "        \"\"\"Prepare final feature set for modeling\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 5: FEATURE PREPARATION\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        categorical_cols = ['venue', 'toss_decision']\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            self.match_df[f'{col}_encoded'] = le.fit_transform(self.match_df[col])\n",
    "            self.label_encoders[col] = le\n",
    "        \n",
    "        # Select features for modeling\n",
    "        feature_cols = [\n",
    "            # Toss features\n",
    "            'toss_winner_is_team1', 'toss_and_bat',\n",
    "            'venue_encoded', 'toss_decision_encoded',\n",
    "            \n",
    "            # Match statistics\n",
    "            'team1_total_runs', 'team1_wickets_lost', 'team1_run_rate',\n",
    "            'team1_boundaries', 'team1_sixes', 'team1_boundary_pct', 'team1_dot_pct',\n",
    "            'team2_total_runs', 'team2_wickets_lost', 'team2_run_rate',\n",
    "            'team2_boundaries', 'team2_sixes', 'team2_boundary_pct', 'team2_dot_pct',\n",
    "            \n",
    "            # Historical features (last 5 matches)\n",
    "            'team1_last5_win_rate', 'team1_last5_avg_runs', 'team1_last5_avg_wickets', 'team1_last5_avg_run_rate',\n",
    "            'team2_last5_win_rate', 'team2_last5_avg_runs', 'team2_last5_avg_wickets', 'team2_last5_avg_run_rate',\n",
    "            \n",
    "            # Head-to-head\n",
    "            'h2h_team1_win_rate', 'h2h_matches'\n",
    "        ]\n",
    "        \n",
    "        # Remove rows with insufficient historical data\n",
    "        initial_rows = len(self.match_df)\n",
    "        self.match_df = self.match_df[self.match_df['h2h_matches'] > 0]\n",
    "        print(f\"\\n✓ Removed {initial_rows - len(self.match_df)} matches with no historical data\")\n",
    "        \n",
    "        self.X = self.match_df[feature_cols].fillna(0)\n",
    "        self.y = self.match_df['team1_won']\n",
    "        self.feature_names = feature_cols\n",
    "        \n",
    "        print(f\"✓ Final feature set: {len(feature_cols)} features\")\n",
    "        print(f\"✓ Training samples: {len(self.X)}\")\n",
    "        print(f\"✓ Class distribution: {self.y.value_counts().to_dict()}\")\n",
    "        \n",
    "        return self.X, self.y\n",
    "    \n",
    "    def split_data(self, test_size=0.2, time_series_split=True):\n",
    "        \"\"\"Split data with proper time-series consideration\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 6: TRAIN-TEST SPLIT\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if time_series_split:\n",
    "            # Split by time to avoid data leakage\n",
    "            split_idx = int(len(self.X) * (1 - test_size))\n",
    "            self.X_train = self.X.iloc[:split_idx]\n",
    "            self.X_test = self.X.iloc[split_idx:]\n",
    "            self.y_train = self.y.iloc[:split_idx]\n",
    "            self.y_test = self.y.iloc[split_idx:]\n",
    "            print(f\"\\n✓ Time-series split (train on past, test on recent matches)\")\n",
    "        else:\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "                self.X, self.y, test_size=test_size, random_state=42, stratify=self.y\n",
    "            )\n",
    "            print(f\"\\n✓ Random stratified split\")\n",
    "        \n",
    "        print(f\"✓ Train set: {len(self.X_train)} samples\")\n",
    "        print(f\"✓ Test set: {len(self.X_test)} samples\")\n",
    "        \n",
    "    def tune_hyperparameters(self, quick_mode=False):\n",
    "        \"\"\"Hyperparameter tuning with GridSearchCV\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 7: HYPERPARAMETER TUNING\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if quick_mode:\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [10, 20],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'max_features': ['sqrt']\n",
    "            }\n",
    "            print(\"\\n⚡ Quick mode enabled (reduced parameter space)\")\n",
    "        else:\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200, 300, 500],\n",
    "                'max_depth': [5, 10, 20, None],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'max_features': ['sqrt', 'log2', None]\n",
    "            }\n",
    "        \n",
    "        rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        print(f\"\\nSearching {np.prod([len(v) for v in param_grid.values()])} combinations...\")\n",
    "        \n",
    "        grid = GridSearchCV(\n",
    "            rf, param_grid, cv=cv, scoring='accuracy', \n",
    "            n_jobs=-1, verbose=1\n",
    "        )\n",
    "        \n",
    "        grid.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        print(f\"\\n✓ Best parameters found:\")\n",
    "        for param, value in grid.best_params_.items():\n",
    "            print(f\"  • {param}: {value}\")\n",
    "        \n",
    "        print(f\"\\n✓ Best CV accuracy: {grid.best_score_:.4f}\")\n",
    "        \n",
    "        self.model = grid.best_estimator_\n",
    "        return grid.best_params_\n",
    "    \n",
    "    def train_model(self, use_tuned=True, **kwargs):\n",
    "        \"\"\"Train the Random Forest model\"\"\"\n",
    "        if not use_tuned or self.model is None:\n",
    "            print(\"\\n\" + \"=\" * 70)\n",
    "            print(\"STEP 7: TRAINING MODEL (Default Parameters)\")\n",
    "            print(\"=\" * 70)\n",
    "            self.model = RandomForestClassifier(\n",
    "                n_estimators=kwargs.get('n_estimators', 200),\n",
    "                max_depth=kwargs.get('max_depth', 20),\n",
    "                min_samples_split=kwargs.get('min_samples_split', 5),\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "            print(\"\\n✓ Model trained successfully\")\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 8: MODEL EVALUATION\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Predictions\n",
    "        y_train_pred = self.model.predict(self.X_train)\n",
    "        y_test_pred = self.model.predict(self.X_test)\n",
    "        \n",
    "        y_test_proba = self.model.predict_proba(self.X_test)[:, 1]\n",
    "        \n",
    "        # Accuracy\n",
    "        train_acc = accuracy_score(self.y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(self.y_test, y_test_pred)\n",
    "        \n",
    "        print(f\"\\n📊 ACCURACY\")\n",
    "        print(f\"  • Training Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "        print(f\"  • Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "        print(f\"  • Overfit Margin: {(train_acc - test_acc)*100:.2f}%\")\n",
    "        \n",
    "        # Classification Report\n",
    "        print(f\"\\n📋 CLASSIFICATION REPORT (Test Set)\")\n",
    "        print(classification_report(self.y_test, y_test_pred, \n",
    "                                     target_names=['Team 2 Wins', 'Team 1 Wins']))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(self.y_test, y_test_pred)\n",
    "        print(f\"\\n📉 CONFUSION MATRIX\")\n",
    "        print(f\"                Predicted\")\n",
    "        print(f\"                0      1\")\n",
    "        print(f\"Actual   0   {cm[0,0]:4d}  {cm[0,1]:4d}\")\n",
    "        print(f\"         1   {cm[1,0]:4d}  {cm[1,1]:4d}\")\n",
    "        \n",
    "        # ROC-AUC\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(self.y_test, y_test_proba)\n",
    "            print(f\"\\n🎯 ROC-AUC Score: {roc_auc:.4f}\")\n",
    "        except:\n",
    "            print(f\"\\n⚠ ROC-AUC not available\")\n",
    "        \n",
    "        # Cross-validation score\n",
    "        cv_scores = cross_val_score(self.model, self.X_train, self.y_train, \n",
    "                                     cv=5, scoring='accuracy')\n",
    "        print(f\"\\n✅ Cross-Validation Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "        \n",
    "        return {\n",
    "            'train_accuracy': train_acc,\n",
    "            'test_accuracy': test_acc,\n",
    "            'cv_scores': cv_scores,\n",
    "            'confusion_matrix': cm\n",
    "        }\n",
    "    \n",
    "    def plot_feature_importance(self, top_n=15):\n",
    "        \"\"\"Visualize feature importance\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 9: FEATURE IMPORTANCE ANALYSIS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        importances = self.model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        print(f\"\\n🔝 Top {top_n} Most Important Features:\")\n",
    "        for i in range(min(top_n, len(self.feature_names))):\n",
    "            idx = indices[i]\n",
    "            print(f\"  {i+1:2d}. {self.feature_names[idx]:40s} {importances[idx]:.4f}\")\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        top_indices = indices[:top_n]\n",
    "        plt.barh(range(top_n), importances[top_indices])\n",
    "        plt.yticks(range(top_n), [self.feature_names[i] for i in top_indices])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title(f'Top {top_n} Feature Importances')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"\\n✓ Feature importance plot saved as 'feature_importance.png'\")\n",
    "        plt.close()\n",
    "        \n",
    "    def predict_match(self, team1_name, team2_name, venue_name, toss_winner_name, toss_decision):\n",
    "        \"\"\"Predict outcome of a new match\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"MATCH PREDICTION\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"\\nTeam 1: {team1_name}\")\n",
    "        print(f\"Team 2: {team2_name}\")\n",
    "        print(f\"Venue: {venue_name}\")\n",
    "        print(f\"Toss Winner: {toss_winner_name}\")\n",
    "        print(f\"Toss Decision: {toss_decision}\")\n",
    "        \n",
    "        # This would require looking up recent stats for these teams\n",
    "        # For demonstration, returning prediction format\n",
    "        print(\"\\n⚠ Note: Real-time prediction requires current team statistics\")\n",
    "        print(\"Use the trained model with actual feature values for predictions\")\n",
    "    \n",
    "    def run_full_pipeline(self, quick_tune=False, time_series_split=True):\n",
    "        \"\"\"Execute complete pipeline\"\"\"\n",
    "        print(\"\\n\" + \"🏏\" * 35)\n",
    "        print(\" \" * 20 + \"CRICKET MATCH PREDICTION SYSTEM\")\n",
    "        print(\" \" * 20 + \"Random Forest with Feature Engineering\")\n",
    "        print(\"🏏\" * 35 + \"\\n\")\n",
    "        \n",
    "        # Execute all steps\n",
    "        self.clean_data()\n",
    "        self.create_match_level_features()\n",
    "        self.create_historical_features(lookback=5)\n",
    "        self.create_head_to_head_features()\n",
    "        self.prepare_features()\n",
    "        self.split_data(test_size=0.2, time_series_split=time_series_split)\n",
    "        self.tune_hyperparameters(quick_mode=quick_tune)\n",
    "        results = self.evaluate_model()\n",
    "        self.plot_feature_importance(top_n=15)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"🎉 PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"\\n📈 Final Test Accuracy: {results['test_accuracy']*100:.2f}%\")\n",
    "        print(f\"✨ Model ready for predictions!\\n\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# USAGE INSTRUCTIONS\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "To use this predictor with your cricket data:\n",
    "\n",
    "1. Load your data (assuming it's in a DataFrame called 'data'):\n",
    "   \n",
    "   predictor = CricketMatchPredictor(data)\n",
    "   \n",
    "2. Run the full pipeline:\n",
    "   \n",
    "   results = predictor.run_full_pipeline(\n",
    "       quick_tune=True,  # Set False for thorough hyperparameter tuning\n",
    "       time_series_split=True  # Train on past matches, test on recent ones\n",
    "   )\n",
    "   \n",
    "3. Access the trained model and results:\n",
    "   \n",
    "   model = predictor.model\n",
    "   X_test = predictor.X_test\n",
    "   y_test = predictor.y_test\n",
    "   predictions = model.predict(X_test)\n",
    "\n",
    "4. View feature importance:\n",
    "   \n",
    "   feature_importance = pd.DataFrame({\n",
    "       'feature': predictor.feature_names,\n",
    "       'importance': predictor.model.feature_importances_\n",
    "   }).sort_values('importance', ascending=False)\n",
    "   \n",
    "   print(feature_importance.head(10))\n",
    "\n",
    "Example complete workflow:\n",
    "   \n",
    "   # Assuming 'data' is your DataFrame with ball-by-ball cricket data\n",
    "   predictor = CricketMatchPredictor(data)\n",
    "   results = predictor.run_full_pipeline(quick_tune=True)\n",
    "   \n",
    "   # Now you can use predictor.model for predictions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "35526008",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = CricketMatchPredictor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "854268f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏\n",
      "                    CRICKET MATCH PREDICTION SYSTEM\n",
      "                    Random Forest with Feature Engineering\n",
      "🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏🏏\n",
      "\n",
      "======================================================================\n",
      "STEP 1: DATA CLEANING\n",
      "======================================================================\n",
      "\n",
      "Missing values before cleaning:\n",
      "wides                     606354\n",
      "noballs                   619247\n",
      "byes                      619645\n",
      "legbyes                   615281\n",
      "penalty                   620633\n",
      "wicket_type               603430\n",
      "player_dismissed          603430\n",
      "other_wicket_type         620646\n",
      "other_player_dismissed    620646\n",
      "winner                     16505\n",
      "bowling_style               3323\n",
      "batting_style               1522\n",
      "dtype: int64\n",
      "\n",
      "Matches: 1173 -> 1118 (removed 55 ties/no results)\n",
      "\n",
      "✓ Data cleaning completed\n",
      "\n",
      "======================================================================\n",
      "STEP 2: FEATURE ENGINEERING\n",
      "======================================================================\n",
      "\n",
      "✓ Created 1118 match-level records\n",
      "✓ Generated 32 initial features\n",
      "\n",
      "======================================================================\n",
      "STEP 3: HISTORICAL FEATURES (Last 5 matches)\n",
      "======================================================================\n",
      "\n",
      "✓ Added historical performance features\n",
      "\n",
      "======================================================================\n",
      "STEP 4: HEAD-TO-HEAD FEATURES\n",
      "======================================================================\n",
      "\n",
      "✓ Added head-to-head features\n",
      "\n",
      "======================================================================\n",
      "STEP 5: FEATURE PREPARATION\n",
      "======================================================================\n",
      "\n",
      "✓ Removed 139 matches with no historical data\n",
      "✓ Final feature set: 28 features\n",
      "✓ Training samples: 979\n",
      "✓ Class distribution: {1: 536, 0: 443}\n",
      "\n",
      "======================================================================\n",
      "STEP 6: TRAIN-TEST SPLIT\n",
      "======================================================================\n",
      "\n",
      "✓ Time-series split (train on past, test on recent matches)\n",
      "✓ Train set: 783 samples\n",
      "✓ Test set: 196 samples\n",
      "\n",
      "======================================================================\n",
      "STEP 7: HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      "\n",
      "⚡ Quick mode enabled (reduced parameter space)\n",
      "\n",
      "Searching 8 combinations...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "✓ Best parameters found:\n",
      "  • max_depth: 20\n",
      "  • max_features: sqrt\n",
      "  • min_samples_split: 2\n",
      "  • n_estimators: 200\n",
      "\n",
      "✓ Best CV accuracy: 0.8966\n",
      "\n",
      "======================================================================\n",
      "STEP 8: MODEL EVALUATION\n",
      "======================================================================\n",
      "\n",
      "📊 ACCURACY\n",
      "  • Training Accuracy: 1.0000 (100.00%)\n",
      "  • Test Accuracy: 0.8980 (89.80%)\n",
      "  • Overfit Margin: 10.20%\n",
      "\n",
      "📋 CLASSIFICATION REPORT (Test Set)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Team 2 Wins       0.92      0.89      0.90       107\n",
      " Team 1 Wins       0.87      0.91      0.89        89\n",
      "\n",
      "    accuracy                           0.90       196\n",
      "   macro avg       0.90      0.90      0.90       196\n",
      "weighted avg       0.90      0.90      0.90       196\n",
      "\n",
      "\n",
      "📉 CONFUSION MATRIX\n",
      "                Predicted\n",
      "                0      1\n",
      "Actual   0     95    12\n",
      "         1      8    81\n",
      "\n",
      "🎯 ROC-AUC Score: 0.9691\n",
      "\n",
      "✅ Cross-Validation Accuracy: 0.8902 (+/- 0.0234)\n",
      "\n",
      "======================================================================\n",
      "STEP 9: FEATURE IMPORTANCE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "🔝 Top 15 Most Important Features:\n",
      "   1. team1_run_rate                           0.1467\n",
      "   2. team2_run_rate                           0.1025\n",
      "   3. team1_dot_pct                            0.0942\n",
      "   4. team2_boundary_pct                       0.0707\n",
      "   5. team1_total_runs                         0.0705\n",
      "   6. team2_dot_pct                            0.0635\n",
      "   7. team1_boundary_pct                       0.0530\n",
      "   8. team2_total_runs                         0.0490\n",
      "   9. team1_boundaries                         0.0467\n",
      "  10. team2_boundaries                         0.0410\n",
      "  11. h2h_team1_win_rate                       0.0296\n",
      "  12. team2_wickets_lost                       0.0243\n",
      "  13. team1_wickets_lost                       0.0211\n",
      "  14. team1_last5_avg_runs                     0.0208\n",
      "  15. team1_last5_avg_run_rate                 0.0206\n",
      "\n",
      "✓ Feature importance plot saved as 'feature_importance.png'\n",
      "\n",
      "======================================================================\n",
      "🎉 PIPELINE COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n",
      "\n",
      "📈 Final Test Accuracy: 89.80%\n",
      "✨ Model ready for predictions!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = predictor.run_full_pipeline(\n",
    "       quick_tune=True,  # Set False for thorough hyperparameter tuning\n",
    "       time_series_split=True  # Train on past matches, test on recent ones\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92776830",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2048302953.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mX_test = predictor.X_test\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "model = predictor.model\n",
    "   X_test = predictor.X_test\n",
    "   y_test = predictor.y_test\n",
    "   predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0231f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "       'feature': predictor.feature_names,\n",
    "       'importance': predictor.model.feature_importances_\n",
    "   }).sort_values('importance', ascending=False)\n",
    "   \n",
    "   print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc8289c",
   "metadata": {},
   "source": [
    "Our task is to predict the match outcome from the first 10 Overs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
